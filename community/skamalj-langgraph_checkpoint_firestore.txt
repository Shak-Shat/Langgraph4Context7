Directory structure:
└── skamalj-langgraph_checkpoint_firestore/
    ├── readme.md
    ├── CHANGELOG.md
    ├── requirement.txt
    ├── src/
    │   └── langgraph_checkpoint_firestore/
    │       ├── __init__.py
    │       ├── firestoreSaver.py
    │       ├── firestoreSerializer.py
    │       ├── LICENSE
    │       └── test.py
    └── tests/
        └── test.py

================================================
FILE: readme.md
================================================
# LangGraph Checkpoint Firestore

This project provides an implementation of a checkpoint saver for LangGraph using Google Firestore. 

## Features
- Save and retrieve langgraph checkpoints in Google Firestore.

## Installation

To install the package, ensure you have Python 3.9 or higher, and run:

```pip install langgraph-checkpoint-firestore```

## Usage

### Setting Up CosmosDBSaver

To use the `FirestoreSaver`, you need to provide google default application authenmtication via environment 


### Example

```
python
from langgraph_checkpoint_firestore import FirestoreSaver
```

# Initialize the saver
Collections - write and checkpoint -  are created if it does not exists
```
#memory = FirestoreSaver(project_id=<project_id>, checkpoints_collection='langchain', writes_collection='langchain_writes')
```
```
with FirestoreSaver.from_conn_info(project_id=<project_id>, checkpoints_collection='langchain', writes_collection='langchain_writes') as memory:
```

## Limitations
List function does not support filters. You can only pass config on thread id to get the list.

```
print(list(memory.list(config=config)))
```
## License

This project is licensed under the MIT License.



================================================
FILE: CHANGELOG.md
================================================
# Changelog

## Version 0.1.3

- **Added**: Configurable checkpoint and writes collection feature.
- **Fixed**: List function bug.

This version introduces a new configurable checkpoint and writes collection feature


================================================
FILE: requirement.txt
================================================



================================================
FILE: src/langgraph_checkpoint_firestore/__init__.py
================================================


from langgraph_checkpoint_firestore.firestoreSaver import FirestoreSaver
from .firestoreSerializer import FirestoreSerializer

__all__ = ["FirestoreSaver", "FirestoreSerializer"]




================================================
FILE: src/langgraph_checkpoint_firestore/firestoreSaver.py
================================================
# create firestore Saver (langgraph checkpointer) basis firestoredb implementation in included code include=src/langgraph_checkpoint_firestore/firestoredbSaver.py 
#  Remember there is no partition key in firestore only unique ID.
# create separate collection for checkpoints and writes. Next level collection will be thread_id and then checkpoint_id
# we have to preserve the function signatures and return values (as in firestoredbsaver) as it is.
# Do provide full and complete code, i.e all function along with Saver in the included file.
# @!

from contextlib import contextmanager
from typing import Any, Iterator, List, Optional, Tuple

from langchain_core.runnables import RunnableConfig

from langgraph.checkpoint.base import WRITES_IDX_MAP, BaseCheckpointSaver, ChannelVersions, Checkpoint, CheckpointMetadata, CheckpointTuple, PendingWrite, get_checkpoint_id

from google.cloud import firestore
from langgraph_checkpoint_firestore.firestoreSerializer import FirestoreSerializer


FIRESTORE_KEY_SEPARATOR = "/"

def _make_firestore_checkpoint_key(thread_id: str, checkpoint_ns: str, checkpoint_id: str) -> str:
    return FIRESTORE_KEY_SEPARATOR.join([
        "checkpoint", thread_id, checkpoint_ns, checkpoint_id
    ])


def _make_firestore_checkpoint_writes_key(thread_id: str, checkpoint_ns: str, checkpoint_id: str, task_id: str, idx: Optional[int]) -> str:
    if idx is None:
        return FIRESTORE_KEY_SEPARATOR.join([
            "writes", thread_id, checkpoint_ns, checkpoint_id, task_id
        ])

    return FIRESTORE_KEY_SEPARATOR.join([
        "writes", thread_id, checkpoint_ns, checkpoint_id, task_id, str(idx)
    ])


def _parse_firestore_checkpoint_key(firestoredb_key: str) -> dict:
    namespace, thread_id, checkpoint_ns, checkpoint_id = firestoredb_key.split(
        FIRESTORE_KEY_SEPARATOR
    )
    if namespace != "checkpoint":
        raise ValueError("Expected checkpoint key to start with 'checkpoint'")

    return {
        "thread_id": thread_id,
        "checkpoint_ns": checkpoint_ns,
        "checkpoint_id": checkpoint_id,
    }


def _parse_firestore_checkpoint_writes_key(firestoredb_key: str) -> dict:
    namespace, thread_id, checkpoint_ns, checkpoint_id, task_id, idx = firestoredb_key.split(
        FIRESTORE_KEY_SEPARATOR
    )
    if namespace != "writes":
        raise ValueError("Expected checkpoint key to start with 'writes'")

    return {
        "thread_id": thread_id,
        "checkpoint_ns": checkpoint_ns,
        "checkpoint_id": checkpoint_id,
        "task_id": task_id,
        "idx": idx,
    }


def _filter_keys(keys: List[str], before: Optional[RunnableConfig], limit: Optional[int]) -> list:
    if before:
        keys = [
            k
            for k in keys
            if _parse_firestore_checkpoint_key(k)["checkpoint_id"]
            < before["configurable"]["checkpoint_id"]
        ]

    keys = sorted(
        keys,
        key=lambda k: _parse_firestore_checkpoint_key(k)["checkpoint_id"],
        reverse=True,
    )
    if limit:
        keys = keys[:limit]
    return keys


def _load_writes(serde: FirestoreSerializer, task_id_to_data: dict[tuple[str, str], dict]) -> list[PendingWrite]:
    writes = [
        (
            task_id,
            data["channel"],
            serde.loads_typed((data["type"], data["value"])),
        )
        for (task_id, _), data in task_id_to_data.items()
    ]
    return writes


def _parse_firestore_checkpoint_data(serde: FirestoreSerializer, key: str, data: dict, pending_writes: Optional[List[PendingWrite]] = None) -> Optional[CheckpointTuple]:
    if not data:
        return None

    parsed_key = _parse_firestore_checkpoint_key(key)
    thread_id = parsed_key["thread_id"]
    checkpoint_ns = parsed_key["checkpoint_ns"]
    checkpoint_id = parsed_key["checkpoint_id"]
    config = {
        "configurable": {
            "thread_id": thread_id,
            "checkpoint_ns": checkpoint_ns,
            "checkpoint_id": checkpoint_id,
        }
    }

    checkpoint = serde.loads_typed((data["type"], data["checkpoint"]))
    
    metadata = serde.loads(data["metadata"])
    parent_checkpoint_id = data.get("parent_checkpoint_id", "")
    parent_config = (
        {
            "configurable": {
                "thread_id": thread_id,
                "checkpoint_ns": checkpoint_ns,
                "checkpoint_id": parent_checkpoint_id,
            }
        }
        if parent_checkpoint_id
        else None
    )
    return CheckpointTuple(
        config=config,
        checkpoint=checkpoint,
        metadata=metadata,
        parent_config=parent_config,
        pending_writes=pending_writes,
    )

class FirestoreSaver(BaseCheckpointSaver):
    def __init__(self, project_id, checkpoints_collection='checkpoints', writes_collection='writes'):
        super().__init__()
        self.client = firestore.Client(project=project_id)
        self.firestore_serde = FirestoreSerializer(self.serde)
        self.checkpoints_collection = self.client.collection(checkpoints_collection)
        self.writes_collection = self.client.collection(writes_collection)

    @classmethod
    @contextmanager
    def from_conn_info(cls,*,project_id: str, checkpoints_collection: str, writes_collection: str) -> Iterator['FirestoreSaver']:
        saver = None
        try:
            saver = FirestoreSaver(project_id, checkpoints_collection, writes_collection)
            yield saver
        finally:
            pass

    def put(self, config: RunnableConfig, checkpoint: Checkpoint, metadata: CheckpointMetadata, new_versions: ChannelVersions) -> RunnableConfig:
        thread_id = config['configurable']['thread_id']
        checkpoint_ns = config['configurable']['checkpoint_ns']
        checkpoint_id = checkpoint['id']
        parent_checkpoint_id = config['configurable'].get('checkpoint_id')
        key = _make_firestore_checkpoint_key(thread_id, checkpoint_ns, checkpoint_id)

        type_, serialized_checkpoint = self.firestore_serde.dumps_typed(checkpoint)
        serialized_metadata = self.firestore_serde.dumps(metadata)
        data = {
            'checkpoint': serialized_checkpoint,
            "checkpoint_key": key,
            'type': type_,
            'metadata': serialized_metadata,
            'parent_checkpoint_id': parent_checkpoint_id if parent_checkpoint_id else ''
        }
        self.checkpoints_collection.document(thread_id).collection(checkpoint_id).document('data').set(data)
        return {
            'configurable': {
                'thread_id': thread_id,
                'checkpoint_ns': checkpoint_ns,
                'checkpoint_id': checkpoint_id
            }
        }

    def put_writes(self, config: RunnableConfig, writes: List[Tuple[str, Any]], task_id: str) -> None:
        thread_id = config['configurable']['thread_id']
        checkpoint_ns = config['configurable']['checkpoint_ns']
        checkpoint_id = config['configurable']['checkpoint_id']

        for idx, (channel, value) in enumerate(writes):
            key = _make_firestore_checkpoint_writes_key(
                thread_id,
                checkpoint_ns,
                checkpoint_id,
                task_id,
                WRITES_IDX_MAP.get(channel, idx),
            )
            type_, serialized_value = self.firestore_serde.dumps_typed(value)
            data = {"checkpoint_key": key, 'channel': channel, 'type': type_, 'value': serialized_value}
            self.writes_collection.document(thread_id).collection(checkpoint_id).document(task_id).set(data)

    def get_tuple(self, config: RunnableConfig) -> Optional[CheckpointTuple]:
        thread_id = config['configurable']['thread_id']
        checkpoint_id = get_checkpoint_id(config)
        
        checkpoint_ns = config['configurable'].get('checkpoint_ns', '')

        checkpoint_key = self._get_checkpoint_key(
            thread_id, checkpoint_ns, checkpoint_id
        )

        if not checkpoint_key:
            return None
        checkpoint_id = _parse_firestore_checkpoint_key(checkpoint_key)["checkpoint_id"]

        doc_ref = self.checkpoints_collection.document(thread_id).collection(checkpoint_id).document('data')
        doc = doc_ref.get()
        if not doc.exists:
            return None

        checkpoint_data = doc.to_dict()
        
        pending_writes = self._load_pending_writes(
            thread_id, checkpoint_ns, checkpoint_id
        )
        return _parse_firestore_checkpoint_data(
            self.firestore_serde, checkpoint_key, checkpoint_data, pending_writes=pending_writes
        )

    def list(self, config: Optional[RunnableConfig], *, filter: Optional[dict[str, Any]] = None, before: Optional[RunnableConfig] = None, limit: Optional[int] = None) -> Iterator[CheckpointTuple]:
        thread_id = config['configurable']['thread_id']
        checkpoint_ns = config['configurable'].get('checkpoint_ns', '')

        checkpoints = self.checkpoints_collection.document(thread_id).collections()
        for checkpoint in checkpoints:
            checkpoint_id = checkpoint.id
            doc_ref = checkpoint.document('data')
            doc = doc_ref.get()
            if doc.exists:
                checkpoint_data = doc.to_dict()
                pending_writes = self._load_pending_writes(thread_id, checkpoint_ns, checkpoint_id)
                yield _parse_firestore_checkpoint_data(self.firestore_serde, checkpoint_data["checkpoint_key"],checkpoint_data, pending_writes)

    def _load_pending_writes(self, thread_id: str, checkpoint_ns: Optional[str] , checkpoint_id: str) -> List[PendingWrite]:
        
        writes_ref = self.writes_collection.document(thread_id).collection(checkpoint_id)  # Use collection instead of collections()
        matching_keys = [write_doc.to_dict() for write_doc in writes_ref.stream()]
        parsed_keys = [
            _parse_firestore_checkpoint_writes_key(key["checkpoint_key"]) for key in matching_keys
        ]
        pending_writes = _load_writes(
            self.firestore_serde,
            {
                (parsed_key["task_id"], parsed_key["idx"]): key
                for key, parsed_key in sorted(
                    zip(matching_keys, parsed_keys), key=lambda x: x[1]["idx"]
                )
            },
        )
        return pending_writes
   
    def _get_checkpoint_key(self, thread_id: str, checkpoint_ns: str, checkpoint_id: Optional[str]) -> Optional[str]:
        if not checkpoint_ns: 
            checkpoint_ns = "default"
        if checkpoint_id:
            return _make_firestore_checkpoint_key(thread_id, checkpoint_ns, checkpoint_id)

        collections = self.checkpoints_collection.document(thread_id).collections()    
        docs = [
            collection.document("data").get().to_dict()
            for collection in collections
            if collection.document("data").get().exists
            ]

        if not docs:
            return None

        latest_doc = max(docs, key=lambda doc: _parse_firestore_checkpoint_key(doc["checkpoint_key"])["checkpoint_id"])
        return latest_doc["checkpoint_key"]


================================================
FILE: src/langgraph_checkpoint_firestore/firestoreSerializer.py
================================================
import base64

class FirestoreSerializer:
    def __init__(self, serde):
        self.serde = serde
    
    def dumps_typed(self, obj):
        type_, data = self.serde.dumps_typed(obj)
        data_base64 = base64.b64encode(data).decode('utf-8')
        return type_, data_base64

    def loads_typed(self, data):
        type_name, serialized_obj = data
        serialized_obj = base64.b64decode(serialized_obj.encode('utf-8'))
        return self.serde.loads_typed((type_name, serialized_obj))

    def dumps(self, obj):
        data = self.serde.dumps(obj)
        data_base64 = base64.b64encode(data).decode('utf-8')
        return data_base64

    def loads(self, serialized_obj):
        serialized_obj = base64.b64decode(serialized_obj.encode('utf-8'))
        return self.serde.loads(serialized_obj)


================================================
FILE: src/langgraph_checkpoint_firestore/LICENSE
================================================
Copyright (c) 2018 The Python Packaging Authority

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.


================================================
FILE: src/langgraph_checkpoint_firestore/test.py
================================================
import getpass
import os, sys
from typing import Literal
from langchain_core.runnables import ConfigurableField
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langgraph.prebuilt import create_react_agent

from firestoreSaver import FirestoreSaver
def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")


_set_env("OPENAI_API_KEY")
model = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)

from typing import Annotated
from typing_extensions import TypedDict

from langgraph.graph import StateGraph, MessagesState, START

memory = FirestoreSaver(project_id="gcdeveloper-new")

def call_model(state: MessagesState):
    #print(state['messages'])
    response = model.invoke(state["messages"])
    return {"messages": response}


builder = StateGraph(MessagesState)
builder.add_node("call_model", call_model)
builder.add_edge(START, "call_model")
graph = builder.compile(checkpointer=memory)

config = {"configurable": {"thread_id": "333"}}
input_message = {"type": "user", "content": "hi! I'm Jeet"}
for chunk in graph.stream({"messages": [input_message]}, config, stream_mode="values"):
    chunk["messages"][-1].pretty_print()

input_message = {"type": "user", "content": "what was my previous name?"}
for chunk in graph.stream({"messages": [input_message]}, config, stream_mode="values"):
    chunk["messages"][-1].pretty_print()

#input_message = {"type": "user", "content": "I live in Pune"}
#for chunk in graph.stream({"messages": [input_message]}, config, stream_mode="values"):
#    chunk["messages"][-1].pretty_print()

input_message = {"type": "user", "content": "Where do I live?"}
for chunk in graph.stream({"messages": [input_message]}, config, stream_mode="values"):
    for m in chunk["messages"]:
        m.pretty_print()




    


================================================
FILE: tests/test.py
================================================
import getpass
import os, sys
from typing import Literal
from langchain_core.runnables import ConfigurableField
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langgraph.prebuilt import create_react_agent

from langgraph_checkpoint_firestore import FirestoreSaver
def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")


_set_env("OPENAI_API_KEY")
model = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)

from typing import Annotated
from typing_extensions import TypedDict

from langgraph.graph import StateGraph, MessagesState, START

#memory = FirestoreSaver(project_id='gcdeveloper-new', checkpoints_collection='langchain', writes_collection='langchain_writes')

def call_model(state: MessagesState):
    response = model.invoke(state["messages"])
    return {"messages": response}

with FirestoreSaver.from_conn_info(project_id='gcdeveloper-new', checkpoints_collection='langchain', writes_collection='langchain_writes') as memory:

    builder = StateGraph(MessagesState)
    builder.add_node("call_model", call_model)
    builder.add_edge(START, "call_model")
    graph = builder.compile(checkpointer=memory)
    
    config = {"configurable": {"thread_id": "10"}}
    #input_message = {"type": "user", "content": "hi! I'm Jeet"}
    #for chunk in graph.stream({"messages": [input_message]}, config, stream_mode="values"):
    #    chunk["messages"][-1].pretty_print()
    
    input_message = {"type": "user", "content": "what's my name?"}
    for chunk in graph.stream({"messages": [input_message]}, config, stream_mode="values"):
        chunk["messages"][-1].pretty_print()
    
    #input_message = {"type": "user", "content": "I live in Pune?"}
    #for chunk in graph.stream({"messages": [input_message]}, config, stream_mode="values"):
    #    chunk["messages"][-1].pretty_print()
    
    input_message = {"type": "user", "content": "Tell me history of my place?"}
    for chunk in graph.stream({"messages": [input_message]}, config, stream_mode="values"):
        chunk["messages"][-1].pretty_print()
    
    
    
    
        

