Directory structure:
â””â”€â”€ agent_hackathon_genAI_career_assistant.ipynb

================================================
FILE: all_agents_tutorials/agent_hackathon_genAI_career_assistant.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
# GenAI Career Assistant Agent â€“ Your Ultimate Guide to a Career in Generative AI!ðŸš€
<a href="https://colab.research.google.com/drive/19lYWHVgRSSyY84HW3WkwJ9OFAA25T8KW?usp=sharing"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
## Overview
Meet the GenAI Career Assistantâ€”an AI-powered mentor designed to simplify and support your journey in Generative AI learning, Resume preparation, Interview assistant and job hunting.
#### Tech Stack
I have used all free Open source.<br>
Langchain,Langgraph, Gemini LLM, DuckDuckGoSearchResult

## Motivation
As GenAI rapidly evolves, more people are eager to learn it for career advancement or transition. However, navigating the vast resources on the internet and platforms like YouTube can be overwhelming, with long videos and scattered, outdated materials making it hard to know where to begin in this busy life. Even using ChatGPT for coding help often yields deprecated code, as GenAI packages and methodsâ€”such as LangChain, LlamaIndex, and Hugging Faceâ€”are updated frequently.

### Key Features

1. **Learning & Content Creation:**
   - Offers tailored learning pathways in GenAI, covering key topics and skills.
   - Assists users in creating tutorials, blogs, and posts based on their interests or queries.
2. **Q&A Support:**
   - Provides on-demand Q&A sessions for users needing guidance on concepts or coding issues.
3. **Resume Building & Review:**
   - One-on-one resume consultations and guidance.
   - Crafts personalized, market-relevant resumes optimized for current job trends.
4. **Interview Preparation:**
   - Hosts Q&A sessions on common and technical interview questions.
   - Simulates real interview scenarios and conducts mock interviews.
5. **Job Search Assistance:**
   - Guides users through the job search process, offering tailored insights and support. 
With the GenAI Career Assistant, your journey to a career in Generative AI becomes organized, personalized, and efficient!

<img src="https://i.imghippo.com/files/xrJV7042k.png" alt="agent" border="0" style="height:20%;width:90%">

## Key Components
1. **State Management**: Using TypedDict to define and manage the state of each customer interaction.
2. **Query Categorization**: Classifying users queries into Learning, Resume Preparation, Interview or Job Search.
3. **Sub Categorization**: Learning(Tutorial, Q&A), Interview(Interview prep,Mock interview).
4. **Response Generation**: Creating appropriate responses based on the query category. Create .md files for Tutorial Blogs, Resume, Mock interview etc.
6. **Workflow Graph**: Utilizing LangGraph to create a flexible and extensible workflow.

## Method Details
1. **Initialization**: Set up the environment and import necessary libraries.
2. **State Definition**: Create a structure to hold query information, category, sub-category, and response.
3. **Node Functions**: Implement separate functions for categorization, and response generation.
4. **Graph Construction**: Use StateGraph to define the workflow, adding nodes and edges to represent the support process.
5. **Conditional Routing**: Implement logic to route queries based on their category and sub- category.
6. **Workflow Compilation**: Compile the graph into an executable application.
7. **Execution**: Process users queries through the workflow and retrieve results.
"""

"""
## Conclusion
The GenAI Career Assistant is more than just a tool; itâ€™s a comprehensive, personalized mentor designed to help you thrive in the rapidly evolving field of Generative AI. From mastering key concepts and building a strong resume to preparing for interviews and navigating the job market, this assistant equips you with everything you need to achieve your career goals. With GenAI Career Assistant by your side, your path to a successful Generative AI career becomes clearer, more manageable, and achievable. Embrace the future of AI with confidence and step into your dream role!
## Future Enhancement
- **Knowledge Base**: Incorporate a resource-rich library with curated links to courses, tutorials, and articles for comprehensive learning support.
- **Multi-Domain Customization**: Expand beyond Generative AI, allowing users to tailor the assistant to any career path, creating a versatile "Dream Job Assistant"
- **Advanced Job Search Tools**: Include an automated job application tracker, enhanced networking features, and guidance on global job opportunities and visas.
"""

"""
### Before starting please install the below packages
"""

pip install langchain==0.3.7 langchain-community==0.3.7 langchain_google_genai==2.0.4 duckduckgo_search==6.3.4 langgraph==0.2.48 python-dotenv

"""
### Here we will import necessary packages:
`langgraph`, `langchain_core`, `langchain_google_genai` - These are important packages for our project.

This code imports necessary libraries to create and interact with a generative AI model from Google. It loads environment variables to securely set up an API key, then configures the model `gemini-1.5-flash` with specific parameters like verbosity (for detailed logs) and temperature (for response creativity). The AI model is instantiated with the API key to enable its use in generating responses.
"""

from typing import Dict, TypedDict
from langgraph.graph import StateGraph, END, START #Importing StateGraph, END, and START from langgraph.graph to define and manage state transitions within a conversational or generative AI workflow.
from langchain_core.prompts import ChatPromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI

from IPython.display import display, Image, Markdown
from langchain_core.runnables.graph import MermaidDrawMethod # to visualize the graph of langgraph node and edges
from dotenv import load_dotenv
import os

# Load environment variables from a .env file to access sensitive information
load_dotenv()

# Set the Gemini API key for authentication with Google Generative AI services
os.environ["GOOGLE_API_KEY"] = os.getenv('GOOGLE_API_KEY')

# Instantiate a chat model using Google's Gemini-1.5-flash with specified configurations
# - verbose=True enables detailed output logs for debugging
# - temperature=0.5 controls the creativity level in responses (lower values make responses more deterministic)
llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash",
                             verbose=True,
                             temperature=0.5,
                             google_api_key=os.getenv("GOOGLE_API_KEY"))


"""
### Defining a State class using TypedDict to specify the structure of state data in the workflow.
- `query`: a string representing the user's input or question.
- `category`: a string indicating the category or type of the query.
- `response`: a string holding the AI model's generated response to the query.
This TypedDict ensures each state has a consistent data format for easier management and readability.
"""

class State(TypedDict):
    query: str
    category: str
    response: str

"""
### First we are defining utilities we will require further
<a href="https://python.langchain.com/docs/how_to/trim_messages/"> ðŸ‘‰ trim_messages <a>

1. **`trim_conversation` Function**: This function limits the conversation history to the latest messages (up to 10), ensuring only recent and relevant messages are retained in the promp
  
2. **`save_file` Function**: Saves data into a uniquely timestamped Markdown file in the `Agent_output` folder, creating the folder if it doesn't exst.

3. **`show_md_file` Function**: Reads and displays the content of a Markdown file within the notebook, rendering it in Markdown form readabilityblity.
lity.

"""

# Importing message types and utilities from langchain_core:
# AIMessage, HumanMessage, SystemMessage: Define different types of messages in a conversation.
# trim_messages: Utility to manage and limit the number of messages in a conversation history.
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage, trim_messages

def trim_conversation(prompt):
    """Trims conversation history to retain only the latest messages within the limit."""
    max_messages = 10  # Limit the conversation history to the latest 10 messages
    return trim_messages(
        prompt,
        max_tokens=max_messages,  # Specifies the maximum number of messages allowed
        strategy="last",  # Trimming strategy to keep the last messages
        token_counter=len,  # Counts tokens/messages using the length of the list
        start_on="human",  # Start trimming when reaching the first human message
        include_system=True,  # Include system messages in the trimmed history
        allow_partial=False,  # Ensures only whole messages are included
    )

import os
from datetime import datetime

def save_file(data, filename):
    """Saves data to a markdown file with a timestamped filename."""
    folder_name = "Agent_output"  # Folder to store output files
    os.makedirs(folder_name, exist_ok=True)  # Creates the folder if it doesn't exist
    
    # Generate a timestamped filename for uniqueness
    timestamp = datetime.now().strftime("%Y%m%d%H%M%S")  # Format: YYYYMMDDHHMMSS
    filename = f"{filename}_{timestamp}.md"
    
    # Define the full file path
    file_path = os.path.join(folder_name, filename)
    
    # Save the data to the file in the specified path
    with open(file_path, "w", encoding="utf-8") as file:
        file.write(data)
        print(f"File '{file_path}' created successfully.")
    
    # Return the full path of the saved file
    return file_path

def show_md_file(file_path):
    """Displays the content of a markdown file as Markdown in the notebook."""
    with open(file_path, 'r', encoding='utf-8') as file:
        content = file.read()
    
    # Render the content in Markdown format within the notebook
    display(Markdown(content))


"""
#### Now We will create class which will be Responsible for Learning(Tutorial and Q&A sessions)
- Checkout here:
<a href="https://python.langchain.com/v0.1/docs/modules/agents/agent_types/tool_calling/">ðŸ‘‰ create_tool_calling_agent <a>
<a href="https://python.langchain.com/docs/how_to/agent_executor/">ðŸ‘‰ AgentExecutor <a>
<a href="https://python.langchain.com/docs/integrations/tools/ddg/">ðŸ‘‰ DuckDuckGoSearchResults <a>

1. **Imports**: 
   - `ChatPromptTemplate` and `MessagesPlaceholder` from `langchain_core.prompts` help structure prompts.
   - `DuckDuckGoSearchResults` from `langchain_community.tools` provides web search capability.
   - `create_tool_calling_agent` and `AgentExecutor` manage agent creation and execution.

2. **`LearningResourceAgent` Class**:
   - **`__init__` Method**: Initializes the chat model (`gemini-1.5-pro`), prompt, and tools (like DuckDuckGo search).
   - **`TutorialAgent` Method**: Runs a search-based tutorial by invoking the model and saving the output as a timestamped Markdown file for review.
   - **`QueryBot` Method**: Conducts a Q&A loop with the user. The conversation is trimmed as it grows, and responses are generated based on updated inputs, with the user able to type 'exit' to end the session.

"""

from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_community.tools import DuckDuckGoSearchResults #searching tools
from langchain.agents import create_tool_calling_agent
from langchain.agents import AgentExecutor

class LearningResourceAgent:
    def __init__(self, prompt):
        # Initialize the chat model, prompt template, and search tools
        self.model = ChatGoogleGenerativeAI(model="gemini-1.5-pro")
        self.prompt = prompt
        self.tools = [DuckDuckGoSearchResults()]

    def TutorialAgent(self, user_input):
        # Set up an agent with tool access and execute a tutorial-style response
        agent = create_tool_calling_agent(self.model, self.tools, self.prompt)
        agent_executor = AgentExecutor(agent=agent, tools=self.tools, verbose=True)
        response = agent_executor.invoke({"input": user_input})
        
        # Save and display the response as a markdown file
        path = save_file(str(response.get('output')).replace("```markdown", "").strip(), 'Tutorial')
        print(f"Tutorial saved to {path}")
        return path

    def QueryBot(self, user_input):
        # Initiates a Q&A loop for continuous interaction with the user
        print("\nStarting the Q&A session. Type 'exit' to end the session.\n")
        record_QA_session = []
        record_QA_session.append('User Query: %s \n' % user_input)
        self.prompt.append(HumanMessage(content=user_input))
        while True:
            # Trim conversation history to maintain prompt size
            self.prompt = trim_conversation(self.prompt)
            
            # Generate a response from the AI model and update conversation history
            response = self.model.invoke(self.prompt)
            record_QA_session.append('\nExpert Response: %s \n' % response.content)
            
            self.prompt.append(AIMessage(content=response.content))
            
            # Display the AI's response and prompt for user input
            print('*' * 50 + 'AGENT' + '*' * 50)
            print("\nEXPERT AGENT RESPONSE:", response.content)
            
            print('*' * 50 + 'USER' + '*' * 50)
            user_input = input("\nYOUR QUERY: ")
            record_QA_session.append('\nUser Query: %s \n' % response.content)
            self.prompt.append(HumanMessage(content=user_input))
            
            # Exit the Q&A loop if the user types 'exit'
            if user_input.lower() == "exit":
                print("Ending the chat session.")
                path = save_file(''.join(record_QA_session),'Q&A_Doubt_Session')
                print(f"Q&A Session saved to {path}")
                return path


"""
### Here we are creating Class for Interview handling(Interview Question Prep and MockInterview)

1. **`InterviewAgent` Class**:
   - **`__init__` Method**: Initializes the model (`gemini-1.5-flash`), prompt, tools (such as DuckDuckGo search), and creates an agent executor with error handling enabled.

2. **`Interview_questions` Method**:
   - Runs a loop for handling interview questions from the user, generating responses using the agent executor. 
   - Responses are stored in `questions_bank` for later reference. The conversation ends when the user types "exit," and the chat history is saved as a Markdown file.

3. **`Mock_Interview` Method**:
   - Simulates a mock interview by initiating a conversation loop. Responses from the model are displayed as "Interviewer" messages, and user inputs as "Candidate" messages.
   - The conversation is trimmed as it grows to maintain prompt size. The interview session ends when the user types "exit," returning a record of the entire interview.

"""

class InterviewAgent:
    def __init__(self, prompt):
        # Initialize the chat model, prompt template, and search tool for use in the agent
        self.model = ChatGoogleGenerativeAI(model="gemini-1.5-flash")
        self.prompt = prompt
        self.tools = [DuckDuckGoSearchResults()]  # Web search tool for retrieving additional information

    def Interview_questions(self, user_input):
        # Holds the conversation history and cumulative questions and answers
        chat_history = []
        questions_bank = ''
        # Create an agent executor with tool access and enable verbose output and error handling
        self.agent = create_tool_calling_agent(self.model, self.tools, self.prompt)
        self.agent_executor = AgentExecutor(agent=self.agent, tools=self.tools, verbose=True, handle_parsing_errors=True)
        while True:
            print("\nStarting the Interview question preparation. Type 'exit' to end the session.\n")
            if user_input.lower() == "exit":
                print("Ending the conversation. Goodbye!")
                break
            
            # Generate a response to the user input and add it to questions_bank
            response = self.agent_executor.invoke({"input": user_input, "chat_history": chat_history})
            questions_bank += str(response.get('output')).replace("```markdown", "").strip() + "\n"
            
            # Update chat history with user input and AI response, limiting history to the last 10 messages
            chat_history.extend([HumanMessage(content=user_input), response["output"]])
            if len(chat_history) > 10:
                chat_history = chat_history[-10:]  # Keep only the last 10 messages
            
            # Get the next input from the user to continue the conversation
            user_input = input("You: ")
        
        # Save the entire question-response history to a markdown file and display it
        path = save_file(questions_bank, 'Interview_questions')
        print(f"Interviews question saved to {path}")
        return path

    def Mock_Interview(self):
        # Start a simulated mock interview session
        print("\nStarting the mock interview. Type 'exit' to end the session.\n")
        
        # Initialize with a starting message and store interview records
        initial_message = 'I am ready for the interview.\n'
        interview_record = []
        interview_record.append('Candidate: %s \n' % initial_message)
        self.prompt.append(HumanMessage(content=initial_message))
        
        while True:
            # Trim conversation history if necessary to maintain prompt size
            self.prompt = trim_conversation(self.prompt)
            
            # Generate a response using the chat model
            response = self.model.invoke(self.prompt)
            
            # Add AI response to the conversation history
            self.prompt.append(AIMessage(content=response.content))
            
            # Output the AI's response as the "Interviewer"
            print("\nInterviewer:", response.content)
            interview_record.append('\nInterviewer: %s \n' % response.content)
            
            # Get the user's response as "Candidate" input
            user_input = input("\nCandidate: ")
            interview_record.append('\nCandidate: %s \n' % user_input)
            
            # Add user input to the conversation history
            self.prompt.append(HumanMessage(content=user_input))
            
            # End the interview if the user types "exit"
            if user_input.lower() == "exit":
                print("Ending the interview session.")
                path = save_file(''.join(interview_record),'Mock_Interview')
                print(f"Mock Interview saved to {path}")
                return path


"""
### Now we will create class for Resume Making which will handle creating resume by chating with user

1. **`ResumeMaker` Class**:
   - **`__init__` Method**: Initializes the chat model (`gemini-1.5-pro`), prompt, and tools (like DuckDuckGo search). Sets up an agent executor with tool access, verbose output, and error handling for generating resume content.

2. **`Create_Resume` Method**:
   - Engages in a conversational loop to gather user input and generate resume content based on responses from the agent.
   - The conversation history (`chat_history`) retains only the latest 10 messages to manage context size.
   - The conversation loop ends when the user types "exit," at which point the final output is saved as a timestamped Markdown file titled "Resume," and the file path is displayed.

"""

class ResumeMaker:
    def __init__(self, prompt):
        # Initialize the chat model, prompt template, and search tool for resume creation
        self.model = ChatGoogleGenerativeAI(model="gemini-1.5-pro")
        self.prompt = prompt
        self.tools = [DuckDuckGoSearchResults()]  # Search tool to gather additional information if needed
        # Create an agent executor with tool access, enabling verbose output and error handling
        self.agent = create_tool_calling_agent(self.model, self.tools, self.prompt)
        self.agent_executor = AgentExecutor(agent=self.agent, tools=self.tools, verbose=True, handle_parsing_errors=True)

    def Create_Resume(self, user_input):
        # Maintain chat history for the resume creation conversation
        chat_history = []
        while True:
            print("\nStarting the Resume create session. Type 'exit' to end the session.\n")
            if user_input.lower() == "exit":
                print("Ending the conversation. Goodbye!")
                break
            
            # Generate a response to user input using the agent and add it to the chat history
            response = self.agent_executor.invoke({"input": user_input, "chat_history": chat_history})
            chat_history.extend([HumanMessage(content=user_input), response["output"]])
            
            # Limit the chat history to the last 10 messages
            if len(chat_history) > 10:
                chat_history = chat_history[-10:]
            
            # Prompt for the next user input to continue the resume creation conversation
            user_input = input("You: ")
        
        # Save the final output as a markdown file and return the file path
        path = save_file(str(response.get('output')).replace("```markdown", "").strip(), 'Resume')
        print(f"Resume saved to {path}")
        return path


"""
### Code Explanation

1. **`JobSearch` Class**:
   - **`__init__` Method**: Initializes the chat model (`gemini-1.5-pro`), prompt, and search tools for job search assistance. Sets up an agent executor to handle conversation flow with verbose output and error handling.

2. **`find_jobs` Method**:
   - Conducts a conversational loop to assist users with job search queries, using the agent's responses based on user input.
   - Retains only the latest 10 messages in `chat_history` to manage the prompt size effectively.
   - The loop ends when the user types "exit," after which the final conversation output is saved to a Markdown file titled "Resume," and the file path is displayed to the user.

"""

class JobSearch:
    def __init__(self, prompt):
        # Initialize the chat model, prompt template, and search tool for job search assistance
        self.model = ChatGoogleGenerativeAI(model="gemini-1.5-pro")
        self.prompt = prompt
        self.tools = DuckDuckGoSearchResults()  # Search tool to find job listings or related information
        # Create an agent executor with tool access, enabling verbose output and error handling
        # self.agent = create_tool_calling_agent(self.model, self.tools, self.prompt)
        # self.agent_executor = AgentExecutor(agent=self.agent, tools=self.tools, verbose=True, handle_parsing_errors=True)

    def find_jobs(self, user_input):
        results = self.tools.invoke(user_input)
        chain = self.prompt | self.model  
        jobs = chain.invoke({"result": results}).content
        
        path = save_file(str(jobs).replace("```markdown", "").strip(), 'Job_search')
        print(f"Jobs saved to {path}")
        return path


"""
### Now we are creating function which will help to categorize our user Input
- We are using <a href="https://python.langchain.com/docs/how_to/few_shot_examples/">ðŸ‘‰ Few Shot prompting </a>(Checkout here) to make our LLM understand the categories.
1. **`categorize` Function**:
   - Categorizes a user query into four main areas: Learning Generative AI, Resume Making, Interview Preparation, or Job Search.
   - Uses a template prompt with examples to guide the AI in choosing the correct category and returns the category number.

2. **`handle_learning_resource` Function**:
   - Determines if a user query about generative AI is related to creating tutorials or asking general questions.
   - Uses a prompt to specify these categories and returns "Tutorial" or "Question" based on the AI's categorization.

3. **`handle_interview_preparation` Function**:
   - Identifies if a user query in the interview category is about a mock interview or general interview questions.
   - Uses examples to instruct the AI on the difference, returning either "Mock" or "Question" to guide further interaction.

"""

def categorize(state: State) -> State:
    """Categorizes the user query into one of four main categories: Learn Generative AI Technology, Resume Making, Interview Preparation, or Job Search."""
    prompt = ChatPromptTemplate.from_template(
        "Categorize the following customer query into one of these categories:\n"
        "1: Learn Generative AI Technology\n"
        "2: Resume Making\n"
        "3: Interview Preparation\n"
        "4: Job Search\n"
        "Give the number only as an output.\n\n"
        "Examples:\n"
        "1. Query: 'What are the basics of generative AI, and how can I start learning it?' -> 1\n"
        "2. Query: 'Can you help me improve my resume for a tech position?' -> 2\n"
        "3. Query: 'What are some common questions asked in AI interviews?' -> 3\n"
        "4. Query: 'Are there any job openings for AI engineers?' -> 4\n\n"
        "Now, categorize the following customer query:\n"
        "Query: {query}"
    )

    # Creates a categorization chain and invokes it with the user's query to get the category
    chain = prompt | llm 
    print('Categorizing the customer query...')
    category = chain.invoke({"query": state["query"]}).content
    return {"category": category}

def handle_learning_resource(state: State) -> State:
    """Determines if the query is related to Tutorial creation or general Questions on generative AI topics."""
    prompt = ChatPromptTemplate.from_template(
        "Categorize the following user query into one of these categories:\n\n"
        "Categories:\n"
        "- Tutorial: For queries related to creating tutorials, blogs, or documentation on generative AI.\n"
        "- Question: For general queries asking about generative AI topics.\n"
        "- Default to Question if the query doesn't fit either of these categories.\n\n"
        "Examples:\n"
        "1. User query: 'How to create a blog on prompt engineering for generative AI?' -> Category: Tutorial\n"
        "2. User query: 'Can you provide a step-by-step guide on fine-tuning a generative model?' -> Category: Tutorial\n"
        "3. User query: 'Provide me the documentation for Langchain?' -> Category: Tutorial\n"
        "4. User query: 'What are the main applications of generative AI?' -> Category: Question\n"
        "5. User query: 'Is there any generative AI course available?' -> Category: Question\n\n"
        "Now, categorize the following user query:\n"
        "The user query is: {query}\n"
    )

    # Creates a further categorization chain to decide between Tutorial or Question
    chain = prompt | llm 
    print('Categorizing the customer query further...')
    response = chain.invoke({"query": state["query"]}).content
    return {"category": response}

def handle_interview_preparation(state: State) -> State:
    """Determines if the query is related to Mock Interviews or general Interview Questions."""
    prompt = ChatPromptTemplate.from_template(
        "Categorize the following user query into one of these categories:\n\n"
        "Categories:\n"
        "- Mock: For requests related to mock interviews.\n"
        "- Question: For general queries asking about interview topics or preparation.\n"
        "- Default to Question if the query doesn't fit either of these categories.\n\n"
        "Examples:\n"
        "1. User query: 'Can you conduct a mock interview with me for a Gen AI role?' -> Category: Mock\n"
        "2. User query: 'What topics should I prepare for an AI Engineer interview?' -> Category: Question\n"
        "3. User query: 'I need to practice interview focused on Gen AI.' -> Category: Mock\n"
        "4. User query: 'Can you list important coding topics for AI tech interviews?' -> Category: Question\n\n"
        "Now, categorize the following user query:\n"
        "The user query is: {query}\n"
    )

    # Creates a further categorization chain to decide between Mock or Question
    chain = prompt | llm 
    print('Categorizing the customer query further...')
    response = chain.invoke({"query": state["query"]}).content
    return {"category": response}


"""
### Now we will create function for job search and Resume making

1. **`job_search` Function**:
   - Sets up a job search agent to find Generative AI job listings based on user input, gathering details like company name, job title, and links.
   - Generates a Markdown (.md) file with results, displayed to the user.

2. **`handle_resume_making` Function**:
   - Creates a customized resume for AI-focused roles by gathering user details (skills, experience, projects) in a structured format.
   - Produces a Markdown (.md) resume template tailored to the Generative AI jobcandidate's performance.

"""

def job_search(state: State) -> State:
    """Provide a job search response based on user query requirements."""
    prompt = ChatPromptTemplate.from_template('''Your task is to refactor and make .md file for the this content which includes
    the jobs available in the market. Refactor such that user can refer easily. Content: {result}''')
    jobSearch = JobSearch(prompt)
    state["query"] = input('Please make sure to mention Job location you want,Job roles\n')
    path = jobSearch.find_jobs(state["query"])
    show_md_file(path)
    return {"response": path}

def handle_resume_making(state: State) -> State:
    """Generate a customized resume based on user details for a tech role in AI and Generative AI."""
    prompt = ChatPromptTemplate.from_messages([
        ("system", '''You are a skilled resume expert with extensive experience in crafting resumes tailored for tech roles, especially in AI and Generative AI. 
        Your task is to create a resume template for an AI Engineer specializing in Generative AI, incorporating trending keywords and technologies in the current job market. 
        Feel free to ask users for any necessary details such as skills, experience, or projects to complete the resume. 
        Try to ask details step by step and try to ask all details within 4 to 5 steps.
        Ensure the final resume is in .md format.'''),
       MessagesPlaceholder("chat_history"),
        ("human", "{input}"),
        ("placeholder", "{agent_scratchpad}"),
    ])
    resumeMaker = ResumeMaker(prompt)
    path = resumeMaker.Create_Resume(state["query"])
    show_md_file(path)
    return {"response": path}


"""
### Next we will create a function for Q&A query bot and Tutorial maker

3. **`ask_query_bot` Function**:
   - Engages in a conversational Q&A session, providing detailed answers to user queries related to Generative AI.
   - Uses back-and-forth interaction to ensure clarity and completeness in responses.

4. **`tutorial_agent` Function**:
   - Generates comprehensive tutorial blogs on Generative AI topics with explanations, example code, and resources for further learning.
   - Saves the tutorial in Markdown (.md) format, designed for clarity and learning support.
"""

def ask_query_bot(state: State) -> State:
    """Provide detailed answers to user queries related to Generative AI."""
    system_message = '''You are an expert Generative AI Engineer with extensive experience in training and guiding others in AI engineering. 
    You have a strong track record of solving complex problems and addressing various challenges in AI. 
    Your role is to assist users by providing insightful solutions and expert advice on their queries.
    Engage in a back-and-forth chat session to address user queries.'''
    prompt = [SystemMessage(content=system_message)]

    learning_agent = LearningResourceAgent(prompt)

    path = learning_agent.QueryBot(state["query"])
    show_md_file(path)
    return {"response": path}

def tutorial_agent(state: State) -> State:
    """Generate a tutorial blog for Generative AI based on user requirements."""
    system_message = '''You are a knowledgeable assistant specializing as a Senior Generative AI Developer with extensive experience in both development and tutoring. 
         Additionally, you are an experienced blogger who creates tutorials focused on Generative AI.
         Your task is to develop high-quality tutorials blogs in .md file with Coding example based on the user's requirements. 
         Ensure tutorial includes clear explanations, well-structured python code, comments, and fully functional code examples.
         Provide resource reference links at the end of each tutorial for further learning.'''
    prompt = ChatPromptTemplate.from_messages([("system", system_message),
            ("placeholder", "{chat_history}"),
            ("human", "{input}"),
            ("placeholder", "{agent_scratchpad}"),])
    #agent_scratchpad is a function that formats the intermediate steps of the agent's actions and observations into a string. 
    #This function is used to keep track of the agent's thoughts or actions during the execution of the program. But its not necessary, we can do without this so we will not include it only define it.
    learning_agent = LearningResourceAgent(prompt)
    path = learning_agent.TutorialAgent(state["query"])
    show_md_file(path)
    return {"response": path}



"""
### Finally we will create function Interview Question prep and Mock interview

5. **`interview_topics_quesions` Function**:
   - Provides a list of interview questions tailored to Generative AI roles, along with references where possible.
   - Outputs a Markdown (.md) document with curated questions based on user requirements.

6. **`mock_interview` Function**:
   - Conducts a simulated Generative AI job interview, interacting with the user in real-time.
   - Provides a post-interview evaluation, summarizing the candidate's performance.
"""

def interview_topics_questions(state: State) -> State:
    """Provide a curated list of interview questions related to Generative AI based on user input."""
    system_message = '''You are a good researcher in finding interview questions for Generative AI topics and jobs.
                     Your task is to provide a list of interview questions for Generative AI topics and job based on user requirements.
                     Provide top questions with references and links if possible. You may ask for clarification if needed.
                     Generate a .md document containing the questions.'''
    prompt = ChatPromptTemplate.from_messages([
                        ("system", system_message),
                        MessagesPlaceholder("chat_history"),
                        ("human", "{input}"),
                        ("placeholder", "{agent_scratchpad}"),])
    interview_agent = InterviewAgent(prompt)
    path = interview_agent.Interview_questions(state["query"])
    show_md_file(path)
    return {"response": path}

def mock_interview(state: State) -> State:
    """Conduct a mock interview for a Generative AI position, including evaluation at the end."""
    system_message = '''You are a Generative AI Interviewer. You have conducted numerous interviews for Generative AI roles.
         Your task is to conduct a mock interview for a Generative AI position, engaging in a back-and-forth interview session.
         The conversation should not exceed more than 15 to 20 minutes.
         At the end of the interview, provide an evaluation for the candidate.'''
    prompt = [SystemMessage(content=system_message)]
    interview_agent = InterviewAgent(prompt)
    path = interview_agent.Mock_Interview()
    show_md_file(path)
    return {"response": path}

"""
### Here, We are creating routing function which will be responsible for conditional edge to give direction after categorization.
- Checkout Here<a href="https://langchain-ai.github.io/langgraph/#:~:text=Conditional%20edge%20means%20that%20the,the%20agent%20(LLM)%20decides.">ðŸ‘‰ Conditional Edge</a>
1. **`route_query` Function**:
   - Routes the main query based on the assigned category number, directing it to the appropriate handler: Learning Resource, Resume Making, Interview Preparation, or Job Search.
   - If the query does not match any predefined categories, prompts the user to ask a more relevant question.

2. **`route_interview` Function**:
   - Routes interview-related queries to specific handlers based on the query's sub-category (either Mock Interview or Interview Topics).
   - If the category is unclear, defaults to "mock_interview."

3. **`route_learning` Function**:
   - Routes learning-related queries, directing them to either a general question bot or a tutorial creation agent.
   - Returns `False` if the query does not clearly fit either sub-category.

"""

def route_query(state: State):
    """Route the query based on its category to the appropriate handler."""
    if '1' in state["category"]:
        print('Category: handle_learning_resource')
        return "handle_learning_resource"  # Directs queries about learning generative AI to the learning resource handler
    elif '2' in state["category"]:
        print('Category: handle_resume_making')
        return "handle_resume_making"  # Directs queries about resume making to the resume handler
    elif '3' in state["category"]:
        print('Category: handle_interview_preparation')
        return "handle_interview_preparation"  # Directs queries about interview preparation to the interview handler
    elif '4' in state["category"]:
        print('Category: job_search')
        return "job_search"  # Directs job search queries to the job search handler
    else:
        print("Please ask your question based on my description.")
        return False  # Returns False if the category does not match any predefined options

def route_interview(state: State) -> str:
    """Route the query to the appropriate interview-related handler."""
    if 'Question'.lower() in state["category"].lower():
        print('Category: interview_topics_questions')
        return "interview_topics_questions"  # Directs to the handler for interview topic questions
    elif 'Mock'.lower() in state["category"].lower():
        print('Category: mock_interview')
        return "mock_interview"  # Directs to the mock interview handler
    else:
        print('Category: mock_interview')
        return "mock_interview"  # Defaults to mock interview if category does not clearly match

def route_learning(state: State):
    """Route the query based on the learning path category."""
    if 'Question'.lower() in state["category"].lower():
        print('Category: ask_query_bot')
        return "ask_query_bot"  # Directs queries to the general question bot
    elif 'Tutorial'.lower() in state["category"].lower():
        print('Category: tutorial_agent')
        return "tutorial_agent"  # Directs queries to the tutorial creation agent
    else:
        print("Please ask your question based on my interview description.")
        return False  # Returns False if no clear category match is found


"""
### Now all set lets create workflow graphs adding edges and nodes.

1. **Workflow Creation**:
   - Initializes a `StateGraph` to define the workflow for query handling, with each node representing a different query handler.

2. **Nodes and Edges**:
   - Adds nodes for each query category and handling function: `categorize`, `handle_learning_resource`, `handle_resume_making`, `handle_interview_preparation`, and `job_search`.
   - Adds edges to connect nodes conditionally based on the category (e.g., `route_query` routes from "categorize" to the appropriate handler).
   - Conditional edges further route within specific categories, such as learning resources (`route_learning`) and interview preparation (`route_interview`).

3. **Workflow Endpoints**:
   - Defines nodes where the workflow terminates (e.g., `handle_resume_making`, `mock_interview`, and `job_search`), connecting them to `END`.

4. **Compilation**:
   - Sets `categorize` as the entry point and compiles the workflow into an executable application, `app`, for handling user queries.

"""

# Create the workflow graph
workflow = StateGraph(State)

# Add nodes for each state in the workflow
workflow.add_node("categorize", categorize)  # Initial categorization node
workflow.add_node("handle_learning_resource", handle_learning_resource)  # Handles learning-related queries
workflow.add_node("handle_resume_making", handle_resume_making)  # Handles resume-making queries
workflow.add_node("handle_interview_preparation", handle_interview_preparation)  # Handles interview prep queries
workflow.add_node("job_search", job_search)  # Handles job search queries
workflow.add_node("mock_interview", mock_interview)  # Handles mock interview sessions
workflow.add_node("interview_topics_questions", interview_topics_questions)  # Handles interview topic questions
workflow.add_node("tutorial_agent", tutorial_agent)  # Tutorial agent for generative AI learning resources
workflow.add_node("ask_query_bot", ask_query_bot)  # General query bot for learning resources

# Define the starting edge to the categorization node
workflow.add_edge(START, "categorize")

# Add conditional edges based on category routing function
workflow.add_conditional_edges(
    "categorize",
    route_query,
    {
        "handle_learning_resource": "handle_learning_resource",
        "handle_resume_making": "handle_resume_making",
        "handle_interview_preparation": "handle_interview_preparation",
        "job_search": "job_search"
    }
)

# Add conditional edges for further routing in interview preparation
workflow.add_conditional_edges(
    "handle_interview_preparation",
    route_interview,
    {
        "mock_interview": "mock_interview",
        "interview_topics_questions": "interview_topics_questions",
    }
)

# Add conditional edges for further routing in learning resources
workflow.add_conditional_edges(
    "handle_learning_resource",
    route_learning,
    {
        "tutorial_agent": "tutorial_agent",
        "ask_query_bot": "ask_query_bot",
    }
)

# Define edges that lead to the end of the workflow
workflow.add_edge("handle_resume_making", END)
workflow.add_edge("job_search", END)
workflow.add_edge("interview_topics_questions", END)
workflow.add_edge("mock_interview", END)
workflow.add_edge("ask_query_bot", END)
workflow.add_edge("tutorial_agent", END)

# Set the initial entry point to start the workflow at the categorize node
workflow.set_entry_point("categorize")

# Compile the workflow graph into an application
app = workflow.compile()


"""
### Lets Visualize our graph

- **Displaying Workflow Graph**:
  - Generates a visual representation of the `app` workflow graph using Mermaid, which is then displayed as a PNG image.
  - The `MermaidDrawMethod.API` method is used to create the PNG, ensuring a clear, structured view of the workflow nodes and their connections.

"""

# Display the workflow graph as a PNG image using Mermaid
display(
    Image(
        app.get_graph().draw_mermaid_png(
            draw_method=MermaidDrawMethod.API,  # Uses Mermaid's API to generate the PNG image of the workflow graph
        )
    )
)

# Output:
#   <IPython.core.display.Image object>

"""
### Final function to Processes a user query using the LangGraph workflow and returns a dictionary containing the query's category and response.
"""

def run_user_query(query: str) -> Dict[str, str]:
    """Process a user query through the LangGraph workflow.
    
    Args:
        query (str): The user's query
        
    Returns:
        Dict[str, str]: A dictionary containing the query's category and response
    """
    results = app.invoke({"query": query})
    return {
        "category": results["category"],
        "response": results["response"]
    }


"""
# ---------------------------Testing Different Scenarios------------------------------
"""

"""
## TEST CASE 1: Creating Tutorials
"""

query = "I want to learn Langchain and langgraph.With usage and concept. Also give coding example implementation for both.Create tutorial for this."
result = run_user_query(query)
result
# Output:
#   Categorizing the customer query...

#   Category: handle_learning_resource

#   Categorizing the customer query further...

#   Category: tutorial_agent

#   

#   

#   [1m> Entering new AgentExecutor chain...[0m

#   [32;1m[1;3m```markdown

#   # LangChain and LangGraph: A Powerful Combination for Generative AI Applications

#   

#   This tutorial introduces LangChain and LangGraph, two powerful libraries that enhance the development of Generative AI applications. We'll explore their core concepts and demonstrate their usage with practical Python code examples.

#   

#   ## LangChain: Building Complex LLM Workflows

#   

#   LangChain simplifies the creation of sophisticated applications using Large Language Models (LLMs). It provides a structured framework for chaining together different components, enabling complex workflows and interactions.

#   

#   ### Core Concepts:

#   

#   * **Chains:**  The fundamental building blocks of LangChain. Chains link together various components like LLMs, prompts, and other utilities to perform specific tasks.

#   * **LLMs:**  LangChain supports integration with various LLMs, allowing flexibility in choosing the best model for your needs.

#   * **Prompts:**  Well-crafted prompts are essential for effective LLM interaction. LangChain provides tools for managing and optimizing prompts.

#   * **Indexes:**  Indexes structure your data for efficient retrieval and usage within LangChain workflows.

#   * **Agents:**  Agents empower LLMs to interact with their environment, making decisions and gathering information.

#   * **Memory:**  Memory components maintain context and history across chain interactions.

#   * **Callbacks:** Callbacks provide insights into chain execution and allow for monitoring and customization.

#   

#   ### Code Example:

#   

#   ```python

#   from langchain.llms import OpenAI

#   from langchain.prompts import PromptTemplate

#   from langchain.chains import LLMChain

#   

#   # Initialize an LLM

#   llm = OpenAI(temperature=0.7)

#   

#   # Define a prompt template

#   template = """Tell me a {adjective} joke about {topic}."""

#   prompt = PromptTemplate(template=template, input_variables=["adjective", "topic"])

#   

#   # Create an LLM chain

#   chain = LLMChain(prompt=prompt, llm=llm)

#   

#   # Execute the chain

#   response = chain.run({"adjective": "funny", "topic": "programming"})

#   print(response)

#   

#   ```

#   

#   ## LangGraph: Visualizing and Analyzing LLM Workflows

#   

#   LangGraph complements LangChain by providing tools to visualize, analyze, and debug LLM workflows. It offers a graphical representation of chains, facilitating understanding and optimization.

#   

#   ### Core Concepts:

#   

#   * **Graph Visualization:** LangGraph creates interactive graphs of LangChain workflows, making it easy to see how components interact.

#   * **Workflow Analysis:**  Analyze chain execution flow, identify bottlenecks, and optimize performance.

#   * **Debugging:**  Visual debugging tools help pinpoint issues in complex chains.

#   

#   ### Code Example (Conceptual - LangGraph integration is evolving):

#   

#   ```python

#   # Hypothetical LangGraph integration - API is subject to change

#   from langgraph import visualize

#   

#   # Visualize the LLM chain

#   visualize(chain)

#   

#   ```

#   

#   ## Resources for Further Learning:

#   

#   * **LangChain Documentation:** [https://python.langchain.com/en/latest/index.html](https://python.langchain.com/en/latest/index.html)

#   * **LangGraph Repository:** [https://github.com/langchain-ai/langchain-langgraph](https://github.com/langchain-ai/langchain-langgraph)

#   

#   

#   This tutorial provided a foundational understanding of LangChain and LangGraph.  Experiment with the code examples and explore the provided resources to delve deeper into these powerful libraries and unlock their full potential for your Generative AI projects.

#   ```[0m

#   

#   [1m> Finished chain.[0m

#   File 'Agent_output\Tutorial_20241117172824.md' created successfully.

#   Tutorial saved to Agent_output\Tutorial_20241117172824.md

#   <IPython.core.display.Markdown object>
#   {'category': 'Category: Tutorial\n',

#    'response': 'Agent_output\\Tutorial_20241117172824.md'}

"""
## TEST CASE 2: Q&A session for Doubts
"""

query = "I am confused between Langgraph and CrewAI when to use what for Agent Creation?"
result = run_user_query(query)
print(result)
# Output:
#   Categorizing the customer query...

#   Category: handle_learning_resource

#   Categorizing the customer query further...

#   Category: ask_query_bot

#   

#   Starting the Q&A session. Type 'exit' to end the session.

#   

#   **************************************************AGENT**************************************************

#   

#   EXPERT AGENT RESPONSE: Let's break down the differences between LangGraph and CrewAI and when you might choose one over the other for agent creation. They target slightly different needs and approaches within the broader field of generative AI-powered agents.

#   

#   **LangGraph (LangChain + Graph Databases):**

#   

#   * **Focus:** Building agents that interact with and reason over knowledge graphs or other structured data sources. LangChain itself is a framework for developing LLM applications, and incorporating a graph database adds a powerful way to represent and query relationships between entities.

#   * **Strengths:**

#       * **Complex Reasoning:** Excels when your agent needs to understand and navigate relationships between different pieces of information.  Think about scenarios like knowledge exploration, question answering over a specific dataset, or tasks requiring multi-hop reasoning.

#       * **Explainability:** The structured nature of a graph database can offer better explainability for the agent's decisions. It can trace back the reasoning path through the graph.

#       * **Data Grounding:** Prevents hallucinations by anchoring the agent's responses to the facts stored in the graph.

#   * **Weaknesses:**

#       * **Setup Complexity:**  Requires setting up and managing a graph database, which adds complexity compared to simpler approaches.

#       * **Data Dependence:**  The agent's knowledge is limited to what's in the graph.  It might struggle with information not represented in the graph structure.

#       * **Less Flexible for Free-Form Conversation:** While possible, adapting LangGraph for highly dynamic, open-ended conversations can be more challenging than using tools designed specifically for dialogue.

#   

#   

#   **CrewAI:**

#   

#   * **Focus:** Building conversational agents and bots, especially for task-oriented dialogues.  It emphasizes the flow of conversation and integrating with various APIs and tools.

#   * **Strengths:**

#       * **Ease of Use for Conversational Flows:** Provides a more streamlined experience for designing conversational flows and handling user interactions.

#       * **Tool Integration:**  Facilitates connecting your agent to external services (e.g., booking systems, databases, APIs) to perform actions within the conversation.

#       * **Multi-Agent Collaboration:** CrewAI supports the development of multiple agents that can collaborate on a task, which can be powerful for complex workflows.

#   * **Weaknesses:**

#       * **Less Suitable for Complex Reasoning:**  While you can implement some logic, CrewAI is not primarily designed for deep reasoning over complex knowledge structures like a graph database.

#       * **Potential for Hallucinations:**  Relies more heavily on LLMs, which can be prone to generating incorrect or nonsensical information if not carefully managed.

#       * **Less Emphasis on Explainability:**  Tracing the reasoning behind an agent's actions might be more difficult compared to a graph-based approach.

#   

#   

#   **In short:**

#   

#   * **Choose LangGraph (LangChain + Graph DB) if:** Your application requires complex reasoning over structured data, explainability is crucial, and you want to minimize hallucinations by grounding responses to a knowledge base.

#   * **Choose CrewAI if:** You need to build a conversational agent for task-oriented dialogues, integrate with various tools and APIs, and potentially orchestrate multiple agents.

#   

#   

#   Could you tell me more about the specific agent you're trying to build? Knowing the context will allow me to give you more tailored advice.  For example, what is the agent's purpose, what kind of data will it interact with, and what are the key functionalities you're aiming for?

#   

#   **************************************************USER**************************************************

#   

#   YOUR QUERY:  I want to create my Custom AI Agents

#   **************************************************AGENT**************************************************

#   

#   EXPERT AGENT RESPONSE: Creating your own custom AI agents is an exciting endeavor! To give you the best advice, let's refine our understanding of your goals.  "Custom AI agents" is a broad term.  Here's a breakdown of key considerations and how they might influence your tool choices:

#   

#   **1. Purpose and Functionality:**

#   

#   * **What is the agent's primary goal?**  Examples: Answering questions, performing tasks, generating creative content, controlling a game character, analyzing data, etc.

#   * **What specific tasks will it perform?**  Be as detailed as possible. For example, if it's a customer service agent, list the types of customer queries it should handle.

#   * **What level of autonomy are you aiming for?** Will the agent operate completely independently, or will there be human oversight?

#   

#   **2. Data and Knowledge:**

#   

#   * **What data will the agent need access to?**  Examples:  A specific knowledge base, a database, real-time data streams, files, APIs, etc.

#   * **How structured is this data?**  Is it neatly organized in a database, or is it unstructured text?

#   * **Will the agent need to learn and update its knowledge over time?**

#   

#   **3. Interaction and Interface:**

#   

#   * **How will users interact with the agent?**  Through a chat interface, voice commands, a graphical interface, API calls, etc.?

#   * **What is the desired level of natural language understanding (NLU)?** Does it need to handle complex language, or are simple commands sufficient?

#   * **Does the agent need to generate natural language responses?**

#   

#   **4. Development Platform and Tools:**

#   

#   * **What is your level of programming expertise?** Are you comfortable with Python and other relevant libraries?

#   * **What resources are available to you?**  Computational power, cloud services, existing datasets, etc.

#   

#   

#   **Example Scenarios and Tool Recommendations:**

#   

#   Let's illustrate with some examples:

#   

#   * **Scenario 1:  A research assistant that can answer questions based on a collection of scientific papers.**

#       * **Likely Tools:** LangChain with a vector database (e.g., Pinecone, Weaviate) to store embeddings of the papers.  This allows for semantic search and retrieval of relevant information.

#   * **Scenario 2:  A customer service chatbot for a website.**

#       * **Likely Tools:**  Dialogflow, Rasa, or Botpress. These platforms specialize in building conversational agents and provide tools for managing dialogue flows.

#   * **Scenario 3:  An agent that can automate tasks in a software application.**

#       * **Likely Tools:**  LangChain with integrations to the specific software APIs.  You might also consider tools like Microsoft's Power Automate or Zapier for simpler automations.

#   * **Scenario 4:  An AI agent that plays a character in a text-based game.**

#       * **Likely Tools:**  LangChain, with a focus on prompt engineering to guide the agent's behavior and personality.

#   

#   

#   Once you provide me with more details about your specific needs, I can give you more targeted advice on the best tools and approaches for building your custom AI agent.

#   

#   **************************************************USER**************************************************

#   

#   YOUR QUERY:  I think i understand now. Thanks for help

#   **************************************************AGENT**************************************************

#   

#   EXPERT AGENT RESPONSE: You're welcome! I'm glad I could help clarify things.  Please don't hesitate to reach out if you have any more questions as you progress with your AI agent development.  Even a small detail about your project can often lead to more specific and helpful recommendations.  Good luck!

#   

#   **************************************************USER**************************************************

#   

#   YOUR QUERY:  exit

#   Ending the chat session.

#   File 'Agent_output\Q&A_Doubt_Session_20241117150253.md' created successfully.

#   Q&A Session saved to Agent_output\Q&A_Doubt_Session_20241117150253.md

#   {'category': 'Category: Question\n', 'response': 'Agent_output\\Q&A_Doubt_Session_20241117150253.md'}


"""
## TEST CASE 3: Interview Question Discussion
"""

query = "I want to discussion Interview question for Gen AI job roles."
result = run_user_query(query)
print(result)
# Output:
#   Categorizing the customer query...

#   Category: handle_interview_preparation

#   Categorizing the customer query further...

#   Category: interview_topics_questions

#   

#   Starting the Interview question preparation. Type 'exit' to end the session.

#   

#   

#   

#   [1m> Entering new AgentExecutor chain...[0m

#   [32;1m[1;3mTo best tailor interview questions for Generative AI job roles, I need some more information.  Please tell me:

#   

#   1. **What specific role are we targeting?** (e.g., Research Scientist, Machine Learning Engineer, Product Manager, Software Engineer focusing on Generative AI)  The questions will differ significantly depending on the role.

#   

#   2. **What is the seniority level?** (e.g., Intern, Junior, Mid-level, Senior)  The difficulty and depth of the questions should scale with experience.

#   

#   3. **What are the key technologies or areas of focus?** (e.g., Large Language Models (LLMs), Diffusion Models, Generative Adversarial Networks (GANs), specific applications like image generation, text generation, code generation)

#   

#   Once I have this information, I can generate a more relevant and effective set of interview questions.

#   [0m

#   

#   [1m> Finished chain.[0m

#   You:  For Mid-level,LLM and Gen AI other techs.

#   

#   Starting the Interview question preparation. Type 'exit' to end the session.

#   

#   

#   

#   [1m> Entering new AgentExecutor chain...[0m

#   [32;1m[1;3mOkay, focusing on a **Mid-level** role with expertise in **LLMs** and other **Generative AI technologies**, here's a markdown file containing interview questions.  This covers a range of topics, from foundational knowledge to practical application and problem-solving.  Remember that the specific questions asked should be adapted based on the candidate's resume and the specific needs of the role.

#   

#   

#   ```markdown

#   # Generative AI Interview Questions - Mid-Level

#   

#   This document outlines interview questions for a mid-level Generative AI role, encompassing expertise in LLMs and other generative AI technologies.

#   

#   

#   ## I. Foundational Knowledge

#   

#   1. **Explain the difference between autoregressive and diffusion models.  Give examples of each and discuss their strengths and weaknesses.**  (Tests understanding of core model architectures)

#   

#   2. **Describe the Transformer architecture.  Explain the role of self-attention and positional encoding.** (Tests understanding of the backbone of many LLMs)

#   

#   3. **What are some common challenges in training LLMs? Discuss methods for mitigating these challenges (e.g., overfitting, vanishing gradients, computational cost).** (Tests practical experience and problem-solving skills)

#   

#   4. **Explain the concept of attention mechanisms. How do they improve upon previous sequence-to-sequence models?** (Tests understanding of a key component of LLMs)

#   

#   5. **What are different ways to evaluate the performance of a generative model? Discuss both quantitative and qualitative metrics.** (Tests understanding of evaluation methodologies)

#   

#   

#   ## II.  LLM Specifics

#   

#   1. **Explain the concept of prompt engineering.  Provide examples of effective prompting techniques and discuss their impact on model output.** (Tests practical experience with LLMs)

#   

#   2. **Describe different methods for fine-tuning LLMs for specific tasks.  Discuss the trade-offs between different approaches.** (Tests knowledge of adaptation techniques)

#   

#   3. **What are some common biases found in LLMs?  How can these biases be mitigated during training or deployment?** (Tests awareness of ethical considerations)

#   

#   4. **Discuss different methods for handling long context lengths in LLMs. What are the limitations and potential solutions?** (Tests understanding of scalability challenges)

#   

#   5. **Compare and contrast different LLM architectures (e.g., GPT, BERT, LaMDA). What are their strengths and weaknesses for different applications?** (Tests broad knowledge of LLM landscape)

#   

#   

#   ## III.  Other Generative AI Technologies

#   

#   1. **Explain the concept of Generative Adversarial Networks (GANs).  Describe the roles of the generator and discriminator.** (Tests understanding of a different generative model architecture)

#   

#   2. **Describe the process of generating images using diffusion models.  What are the advantages and disadvantages compared to GANs?** (Tests knowledge of another generative model)

#   

#   3. **Discuss the ethical implications of generative AI, including potential for misuse and bias amplification.** (Tests awareness of responsible AI development)

#   

#   

#   ## IV.  Practical Application and Problem Solving

#   

#   1. **Describe a project where you used generative AI to solve a real-world problem.  What were the challenges, and how did you overcome them?** (Tests practical experience and problem-solving abilities â€“ this should be a detailed discussion)

#   

#   2. **Design a system for generating realistic human faces using generative AI.  Discuss the technical challenges and potential solutions.** (Tests ability to design a generative AI system)

#   

#   3. **You are tasked with improving the efficiency of an existing LLM.  Describe your approach, considering factors such as computational resources, model size, and performance metrics.** (Tests practical problem-solving skills)

#   

#   4. **How would you approach debugging a generative model that is producing nonsensical or low-quality outputs?** (Tests practical troubleshooting skills)

#   

#   

#   ## V.  System Design and Deployment

#   

#   1.  **Design a system for deploying an LLM as an API.  Consider aspects such as scalability, latency, and security.** (Tests understanding of deployment considerations)

#   

#   2. **Discuss strategies for monitoring and maintaining the performance of a deployed generative AI model.** (Tests understanding of model lifecycle management)

#   

#   

#   This list is not exhaustive, and the specific questions asked should be tailored to the candidate's experience and the requirements of the role.  Remember to also assess soft skills such as communication, teamwork, and problem-solving abilities throughout the interview process.

#   ```

#   [0m

#   

#   [1m> Finished chain.[0m

#   You:  Can you give me questions for Langchain and Langgraph.

#   

#   Starting the Interview question preparation. Type 'exit' to end the session.

#   

#   

#   

#   [1m> Entering new AgentExecutor chain...[0m

#   [32;1m[1;3mOkay, let's add some questions specifically targeting Langchain and LangGraph to the existing interview questions.  We'll integrate them into the existing markdown structure.  Since LangChain and LangGraph are relatively new, the questions will focus on understanding their core concepts and how they relate to broader Generative AI principles.

#   

#   

#   ```markdown

#   # Generative AI Interview Questions - Mid-Level

#   

#   This document outlines interview questions for a mid-level Generative AI role, encompassing expertise in LLMs and other generative AI technologies, including LangChain and LangGraph.

#   

#   

#   ## I. Foundational Knowledge

#   

#   [Existing questions from previous response]

#   

#   

#   ## II.  LLM Specifics

#   

#   [Existing questions from previous response]

#   

#   

#   ## III.  Other Generative AI Technologies

#   

#   [Existing questions from previous response]

#   

#   

#   ## IV. LangChain and LangGraph

#   

#   1. **What is LangChain, and what are its key components?  Describe how it simplifies the development of LLM-powered applications.** (Tests understanding of LangChain's core functionality)

#   

#   2. **Explain the concept of chains and agents in LangChain.  Provide examples of how they can be used to build complex LLM applications.** (Tests understanding of LangChain's architectural patterns)

#   

#   3. **How does LangChain handle memory in LLM applications?  Discuss different memory types and their use cases.** (Tests understanding of state management in LangChain)

#   

#   4. **Describe how you would use LangChain to build an application that integrates multiple LLMs or other tools (e.g., databases, APIs).** (Tests ability to apply LangChain in a practical scenario)

#   

#   5. **What is LangGraph? How does it differ from other knowledge graph approaches, and what are its advantages and disadvantages for building LLM applications?** (Tests understanding of LangGraph's unique features)

#   

#   6. **How can LangGraph be used to enhance the capabilities of LLMs?  Provide specific examples of how it improves reasoning, knowledge access, or context management.** (Tests understanding of LangGraph's applications)

#   

#   7. **Compare and contrast LangChain and LangGraph.  Discuss scenarios where one might be preferred over the other.** (Tests ability to compare and contrast different tools)

#   

#   8. **Describe a potential project where you would utilize both LangChain and LangGraph to build a sophisticated LLM-powered application.  Outline the architecture and key components.** (Tests ability to design a complex system using both tools)

#   

#   

#   ## V.  Practical Application and Problem Solving

#   

#   [Existing questions from previous response]

#   

#   

#   ## VI.  System Design and Deployment

#   

#   [Existing questions from previous response]

#   

#   

#   This list is not exhaustive, and the specific questions asked should be tailored to the candidate's experience and the requirements of the role.  Remember to also assess soft skills such as communication, teamwork, and problem-solving abilities throughout the interview process.

#   ```

#   [0m

#   

#   [1m> Finished chain.[0m

#   You:  exit

#   

#   Starting the Interview question preparation. Type 'exit' to end the session.

#   

#   Ending the conversation. Goodbye!

#   File 'Agent_output\Interview_questions_20241117151913.md' created successfully.

#   Interviews question saved to Agent_output\Interview_questions_20241117151913.md

#   <IPython.core.display.Markdown object>
#   {'category': 'Category: Question\n', 'response': 'Agent_output\\Interview_questions_20241117151913.md'}


"""
## TEST CASE 4: Mock Interview with Evaluation Feedback
"""

query = "I need mock interview to practice."
result = run_user_query(query)
result
# Output:
#   Categorizing the customer query...

#   Category: handle_interview_preparation

#   Categorizing the customer query further...

#   Category: mock_interview

#   

#   Starting the mock interview. Type 'exit' to end the session.

#   

#   

#   Interviewer: Great! Welcome.  My name is Alex, and I'll be conducting your interview today for the Generative AI Engineer position.  Let's start with a brief introduction from you. Tell me about yourself and your experience relevant to this role.  We have your resume, but I'd like to hear it in your own words.  Keep it to about 2-3 minutes.

#   

#   

#   Candidate:  Iâ€™m Karan, and Iâ€™m currently focused on advancing my skills and contributions in Generative AI. My journey started with a solid foundation in Computer Science, where I developed a strong interest in AI and machine learning. Over the years, Iâ€™ve built a range of projects that have helped me gain expertise in several core areas of this role.  One of my most impactful experiences was working on an end-to-end Legal Case Identification system for Verinext and Pondlehocky. This project involved integrating Gen-AI to automate case assignments. I led a team to develop a pipeline that included NLP, GPT, prompt engineering, and Litify DB integration, ultimately enabling efficient case handling through an AI-driven model.  Iâ€™ve also worked on an Automatic Number Plate Recognition project for NPCI. This required designing and deploying a real-time ANPR solution using transfer learning, Deepstream, and OCR. I collaborated closely with my team on model improvement and pipeline optimization to ensure the project could effectively replace existing toll services.  Beyond my technical skills, I bring a strategic approach to problem-solving and a knack for diving into the nuances of machine learning models, optimizing them to fit specific business needs. Iâ€™m passionate about harnessing AI to address real-world challenges, and Iâ€™m excited about the possibility of contributing my skills and learning further with your team.

#   

#   Interviewer: That's a strong introduction, Karan.  Your projects demonstrate a good understanding of the practical applications of Generative AI. Let's delve a bit deeper.  You mentioned prompt engineering in your Legal Case Identification project. Can you describe a challenging prompt engineering problem you faced and how you solved it?  What metrics did you use to evaluate the success of your prompt engineering efforts?

#   

#   

#   Candidate:  Certainly, Alex.  In the Legal Case Identification project, a significant challenge in prompt engineering arose when trying to accurately classify complex case types from unstructured legal data. The prompts needed to be crafted carefully to balance specificity with flexibility, as the language in legal documents can vary widely. One particular issue was handling nuanced legal terms and context-specific language that often influenced the interpretation of a caseâ€™s category.  To address this, I experimented with structured prompt templates that included both contextual keywords and specific qualifiers. For example, rather than just asking the model to classify a "personal injury" case, I structured prompts to include additional context like, "Identify if this case involves physical harm due to an accident or negligence," which guided the model to focus on relevant legal scenarios.  For evaluation, I used precision, recall, and F1 scores to measure how accurately the prompts identified cases correctly across categories. Additionally, we monitored the modelâ€™s consistency by testing it on a set of challenging cases with subtle differences to see if the prompts led to consistent responses. I also tracked user feedback from legal experts who verified if the classifications aligned with practical expectations.  This iterative approach, along with close collaboration with subject matter experts, allowed me to refine prompts effectively. It was a great learning experience in balancing prompt detail and adaptability while ensuring reliable, high-quality results for the client.

#   

#   Interviewer: Excellent.  That demonstrates a good understanding of prompt engineering and evaluation metrics.  Now, let's shift gears slightly.  Generative AI models can sometimes produce biased or inaccurate outputs.  How would you address such issues in a production environment?

#   

#   

#   

#   

#   Candidate:  Thank you, Alex; thatâ€™s an important consideration.  In a production environment, handling bias and inaccuracies in Generative AI outputs requires a proactive, multi-layered approach. Hereâ€™s how Iâ€™d approach it:  Data and Model Auditing: Iâ€™d start by auditing the training data to identify and mitigate any inherent biases. This might involve using a diverse dataset or adding counterexamples to balance the perspectives presented in the modelâ€™s outputs. Model fine-tuning can help adjust any biases found in pre-trained models by focusing on more representative or neutral datasets.  Prompt Design and Constraints: In prompt engineering, Iâ€™d craft prompts that guide the model toward neutral and accurate responses. For instance, setting constraints in the prompt to avoid speculative or potentially biased language can help. Additionally, Iâ€™d use prompt templates that explicitly frame questions to elicit factual and context-appropriate information.  Post-Processing and Filtering: After generating outputs, Iâ€™d implement a filtering or post-processing layer that flags any content that seems potentially biased or incorrect. For example, sentiment analysis or bias detection algorithms can help flag outputs, allowing for an additional layer of human review or correction before the final output is published.

#   

#   Interviewer: Good.  You've covered some key aspects.  One last question:  Describe your preferred approach to staying up-to-date with the rapidly evolving field of Generative AI.

#   

#   

#   

#   Candidate:  To stay current in Generative AI, I rely on a structured approach that combines both learning from established resources and exploring emerging trends:  Research Papers and Journals: I regularly read papers from sources like arXiv and conferences such as NeurIPS, ICML, and CVPR. Following key researchers and institutions helps me stay updated on cutting-edge techniques, and I make it a habit to read and analyze at least one new paper each week, focusing on both theoretical advances and practical applications.  Community and Open-Source Contributions: I participate in open-source projects on platforms like GitHub, which keeps me connected with the latest tools and libraries. Additionally, contributing to or following repositories in frameworks like Hugging Face or PyTorch gives me hands-on exposure to practical advancements in model development and deployment.  Online Courses and Workshops: I engage in online courses or certifications, especially when new architectures or methodologies gain traction, such as diffusion models or prompt engineering techniques. Platforms like Coursera and specialized workshops provide structured, in-depth content that complements hands-on experience.  Podcasts and Newsletters: I subscribe to AI-focused newsletters like "The Batch" by Andrew Ng and listen to podcasts such as "Lex Fridman" and "Data Skeptic," which often feature industry experts discussing the latest trends and breakthroughs. This is a great way to get a broader perspective on AI developments and practical applications.

#   

#   Interviewer: Excellent. Thank you, Karan. That concludes our interview.  I appreciate you taking the time to speak with me today.

#   

#   

#   **Evaluation:**

#   

#   Karan demonstrated a strong understanding of Generative AI concepts and their practical application. His project descriptions were detailed and showcased his ability to tackle complex problems and evaluate results effectively.  He articulated a well-rounded approach to addressing bias and maintaining accuracy in production environments. His commitment to continuous learning is also commendable. While he could have provided more specific examples in some areas, overall, he presented himself as a strong candidate for the Generative AI Engineer position.  I would recommend him for the next stage of the interview process.

#   

#   

#   Candidate:  exit

#   Ending the interview session.

#   File 'Agent_output\Mock_Interview_20241117174111.md' created successfully.

#   Mock Interview saved to Agent_output\Mock_Interview_20241117174111.md

#   <IPython.core.display.Markdown object>
#   {'category': 'Category: Mock\n',

#    'response': 'Agent_output\\Mock_Interview_20241117174111.md'}
#   Ending the conversation. Goodbye!

#   File 'Agent_output\Interview_questions_20241117005746.md' created successfully.

#   <IPython.core.display.Markdown object>
#   {'category': 'Category: Question\n',

#    'response': 'Agent_output\\Interview_questions_20241117005746.md'}

"""
## TEST CASE 5: Resume Modification Based on Job Description
"""

query = "Can you help me to modify my resume based on job description"
result = run_user_query(query)
result
# Output:
#   Categorizing the customer query...

#   Category: handle_resume_making

#   

#   Starting the Resume create session. Type 'exit' to end the session.

#   

#   

#   

#   [1m> Entering new AgentExecutor chain...[0m

#   [32;1m[1;3mI can definitely help you with that! To tailor your resume effectively, I'll need some information from you. First, could you please share:

#   

#   1. Your current resume (in any format).

#   2. The job description of the role you're targeting.

#   3. Your LinkedIn profile URL (optional).

#   [0m

#   

#   [1m> Finished chain.[0m

#   You:  SKILLS:   Technical skills:   â€¢ Demonstrated work experience with natural language processing techniques to drive business value. Experience building user-centric AI products/features is highly valuable.    â€¢ Knowledge in Hypothesis testing, Statistical Methods, Sampling Theory, Experimental Design    â€¢ Familiarity with common advanced analysis tools â€“ SQL & Python/R    â€¢ Demonstrated familiarity (work experience, GitHub account) with OOP concepts. Expertise in Python is a big plus.    â€¢ Experience with cloud computing (AWS) & MLOps is a plus.    â€¢ Strong knowledge of Machine Learning & Deep Learning   Soft/Leadership skills:   â€¢ Use business acumen and analytical skills to identify opportunities, estimate potential, layout strategy roadmaps to solve complex business problems.    â€¢ Be motivated to explore and identify opportunities from scratch by thinking backwards on problem solving by putting users and data at the center of analysis and decision making.    â€¢ Be responsible for using analytical techniques like Machine learning, Natural Language Processing, and advanced data visualizations to improve Asurionâ€™s customersâ€™ experiences.    â€¢ Deploy ML solutions in production environment    â€¢ Design statistical tests for product experiments, measure impact, derive insights and provide recommendations    â€¢ Work closely with product managers to identify and answer important product questions that help improve outcomes      Resume: KARAN SHRESTHA LinkedIn | 747-295-9996 | ks.karanshrestha@gmail.com | GitHub Seasoned Data Scientist skilled in Python, Machine Learning, NLP, and Deep Learning, Generative AI, Prompt Engineering with 4.5 years of experience. Proven ability in data science, excellent communication skills, and analytical skills. Effective team player with strong time management. Keen learner with a proactive attitude. Skills ____________________________________________________________________________________________ â€¢ Python | SQL | C# | Tensorflow | Pytorch | Numpy | NLTK | Pandas | Natural Language Processing | Machine Learning| Database query | â€¢ Computer Vision | Transformers | MXNet | Deep Learning | Anomaly detection | Scikit-learn | CNN | RNN | LSTM -Neural networks | â€¢ AWS | JavaScript | REST API | LLMs-Large Language Models | Keras | Predictive Modeling | Generative AI | Prompt Engineering | Neo4j â€¢ Tableau | Power BI | Fine Tuning | Problem solving | Web Development | PySpark | GCP | Azure | Statistics | Statistical modeling | R Experience _______________________________________________________________________________________ Senior Data Scientist FreightMango Gurgaon, India 06/2023 â€“ 12/2023 â€¢ Applied data preprocessing techniques, including data collection and cleaning, to prepare datasets for Machine learning models. â€¢ Tuned and optimized datasets through advanced data preprocessing techniques for machine learning models. â€¢ Engineered an automated customer quotation document scanning pipeline, boosting customer acquisition by 40%. â€¢ Drive the vision of the product, ensuring alignment with business goals. Implement networking protocols and ensure robust product security. Conducted research to identify industry trends, applying findings to product innovation. â€¢ Applied machine learning (ML) algorithms to optimize finance-related applications, enhancing the accuracy and efficiency of financial forecasting models. â€¢ Developed ML models and maintained information systems to manage and process large data sets, ensuring data integrity and availability for machine learning projects. â€¢ Demonstrated a high level of attention to detail in data preprocessing, model tuning, and system optimization, ensuring accuracy and reliability in deliverables. â€¢ Collaborate with cross-functional teams to develop innovative solutions. Apply analytical skills to solve complex problems and improve basic functionalities. Managed social media campaigns, boosting engagement by 30% with targeted content strategies. Software Engineer DataNova Noida, India 02/2019 - 06/2023 â€¢ Conducted image annotation, text data cleaning, text vectorization, manipulation, and data preprocessing for Machine learning projects. â€¢ Feature Engineering and created data visualizations to support data-driven decisions. Execute on design, build, analysis and validation of  data analytics, modeling, and machine learning techniques â€¢ In-depth expertise with a rich repertoire of Regression, Classification, Clustering, and Dimensionality reduction algorithms. â€¢ Delivered pre-trained and fine-tuned neural network models using TensorFlow for internal projects, including object detection and automated chatbots using NLP. â€¢ Collaborated with cross-functional teams to deploy machine learning solutions, enhancing performance for perception tasks like Object  Detection. â€¢ Developed predictive models using algorithms such as Kernel-KNN, Decision Trees, Random Forest, Gradient Boosting, SVMs, and XgBoost. â€¢ Ensure scalability, security, and performance of the applications. Conduct thorough testing and monitoring to ensure high-quality deliverables. Developed and executed strategic plans, driving growth and improving efficiency. â€¢ Engage in code review processes to maintain code quality and best practices. Utilize metrics and analytics to measure and improve product performance. Created and refined project specifications to align with client requirements and industry standards. â€¢ Developed innovative machine learning solutions and computer vision models, significantly enhancing system performance and accuracy. â€¢ Contribute to the development of ML models and their integration into the product. Provide written and verbal communication on project progress and technical issues. â€¢ Regularly monitored the status of machine learning models and data pipelines, ensuring optimal performance and accuracy through continuous evaluation and fine-tuning. Education ________________________________________________________________________________________ Master of Science San Francisco Bay University Fremont, CA, USA 01/2024 - Present â€¢ Major in Computer Science (3.93 GPA) Bachelor of Science ITS Engineering College Greater Noida, India 05/2015 - 06/2019 â€¢ Major in Computer Science & Engineering (3.62 GPA) Projects __________________________________________________________________________________________ â€¢ WAFER SENSOR FAULT CLASSIFICATION: Predict the quality of the wafer whether good or bad based on the different sensor values for each wafer. A wafer is a thin semiconductor used in various electronic devices. Technology: Python, SQL, Machine learning, RandomForest Classifier, Data Validation, Preprocessing, K Means++ Clustering, Classification, Hyperparameter tuning. â€¢ HAND DETECTION-Shredder Machine: Detect the hands of the workers working with the shredder machine and stop the machine if hands come near the machine to prevent injury. Technology: Python, SQL, Tensorflow object detection framework-SSDlite â€¢ ANPR (Automatic Number Plate Recognition): Worked on end-to-end ANPR for NPCI , installed on Mumbai Marine Lines running on real time. ANPR is Automatic Number Plate Recognition system , Purpose for this Solution is to replace Fastag and convert all toll services with ANPR solution. Technology: Computer vision, Transfer learning, Deepstream, Docker, GCP, Yolo, Tracker, paddel, dbnet, OCR(CRNN, paddel OCR,tensorRT), ML-Flow, Python, OpenCV, Pandas. â€¢ VERINEXT(PondLehocky) on Project Legal-Case-Identification (LCI): LCI( Legal-Case-Identification) is a legal domain project , This Solution is for US legal firms to replace their Manual processes to assign case to suitable handling firm with Gen-AI solution with Littify DB. Technology: Gen-AI, NLP, GPT, Prompt engineering, LangChain, Authentication API , Litify, Deep learning Algo, AZURE-API. â€¢ FM QUOTATION REQUEST - OCR: A fully automated OCR model that takes input as a pdf or doc file scans it and retrieves information regarding quotation of the user for delivery and pick up details of requests and process it. Technology: Natural Language Processing, Spacy, NER, Data cleaning. â€¢ CONCRETE STRENGTH PREDICTION: A regression model to predict the concrete compressive strength based on quantity of different components of mixtures and cement. Technology: Python,SQL, Machine learning, XGboost Regressor, Data Validation, Preprocessing, Clustering, Hyperparameter tuning. â€¢ WEBSHOP-CUSTOMER REVIEWS SENTIMENTS: Classifies the reviews of all the customers visited in Web-Shop and gives the different sentiment analysis reports. Technology: NLP, Naive bayes, Support Vector machine, TFIDF, SQL. Mentorship _______________________________________________________________________________________ â€¢ Data Science Tutor: Programming | Data Science | Machine Learning | Data Visualization. Certificates ___________________________________________________________________________________________ â€¢ Oracle Cloud Infrastructure 2024 Generative AI Certified Professional. Link â€¢ Gold Badge (5 Star) for Python on HackerRank. Link â€¢ Data Scientist 1 year Master Professional Program. Link â€¢ Certificate of Training in MACHINE LEARNING Advance course. Link

#   

#   Starting the Resume create session. Type 'exit' to end the session.

#   

#   

#   

#   [1m> Entering new AgentExecutor chain...[0m

#   [32;1m[1;3m```markdown

#   # Karan Shrestha

#   [LinkedIn](LinkedIn) | 747-295-9996 | ks.karanshrestha@gmail.com | [GitHub](GitHub)

#   

#   ## Summary

#   

#   Highly motivated and results-oriented Data Scientist with 4.5 years of experience specializing in Machine Learning, Natural Language Processing (NLP), Deep Learning, Generative AI, and Prompt Engineering. Proven ability to leverage data-driven insights to solve complex business problems, with a strong focus on building user-centric AI products. Expertise in Python, cloud computing (AWS), and MLOps, along with excellent communication and teamwork skills.  Passionate about exploring and identifying opportunities to improve customer experiences through innovative AI solutions.

#   

#   ## Skills

#   

#   **Technical Skills:** Python, SQL, C#, TensorFlow, PyTorch, NumPy, NLTK, Pandas, Scikit-learn, Transformers, MXNet, Keras, Deep Learning, CNN, RNN, LSTM, Computer Vision, Anomaly Detection, AWS, JavaScript, REST API, LLMs (Large Language Models), Generative AI, Prompt Engineering, Fine-tuning, PySpark, GCP, Azure,  Statistics, Statistical Modeling, R, Neo4j

#   

#   **Soft/Leadership Skills:**  Problem-solving, Business Acumen, Analytical Skills, Strategic Planning, Communication (Written & Verbal), Teamwork, Time Management,  Product Vision, Cross-functional Collaboration, Data Visualization (Tableau, Power BI)

#   

#   

#   ## Experience

#   

#   **Senior Data Scientist, FreightMango, Gurgaon, India (06/2023 â€“ 12/2023)**

#   

#   * Engineered an automated customer quotation document scanning pipeline using OCR and NLP, resulting in a 40% increase in customer acquisition.

#   * Applied Machine Learning (ML) algorithms to optimize finance-related applications, improving the accuracy and efficiency of financial forecasting models.

#   * Developed and maintained information systems for managing and processing large datasets for machine learning projects.

#   * Conducted research on industry trends and applied findings to product innovation, driving the product vision and ensuring alignment with business goals.

#   * Implemented networking protocols and ensured robust product security.

#   * Collaborated with cross-functional teams to develop innovative solutions and improve core functionalities.

#   * Managed social media campaigns, increasing engagement by 30% through targeted content strategies.

#   

#   **Software Engineer, DataNova, Noida, India (02/2019 - 06/2023)**

#   

#   * Developed and delivered pre-trained and fine-tuned neural network models using TensorFlow for internal projects, including object detection and automated chatbots using NLP.

#   * Collaborated with cross-functional teams to deploy machine learning solutions, enhancing performance for perception tasks like object detection.

#   * Developed predictive models using algorithms such as Kernel-KNN, Decision Trees, Random Forest, Gradient Boosting, SVMs, and XGBoost.

#   * Conducted image annotation, text data cleaning, text vectorization, and data preprocessing for machine learning projects.

#   * Created data visualizations to support data-driven decisions.

#   * Contributed to the development of ML models and their integration into the product.

#   * Regularly monitored and fine-tuned machine learning models and data pipelines to ensure optimal performance and accuracy.

#   

#   

#   ## Education

#   

#   **Master of Science in Computer Science (3.93 GPA), San Francisco Bay University, Fremont, CA, USA (01/2024 â€“ Present)**

#   

#   **Bachelor of Science in Computer Science & Engineering (3.62 GPA), ITS Engineering College, Greater Noida, India (05/2015 - 06/2019)**

#   

#   

#   ## Projects

#   

#   * **Wafer Sensor Fault Classification:** Developed a machine learning model using Random Forest Classifier and K-Means++ Clustering to predict wafer quality based on sensor data.

#   * **Hand Detection - Shredder Machine:** Implemented a real-time hand detection system using TensorFlow Object Detection framework (SSDlite) to prevent workplace injuries.

#   * **ANPR (Automatic Number Plate Recognition):** Developed an end-to-end ANPR system for NPCI using computer vision, transfer learning, and deep learning techniques.

#   * **Verinext (PondLehocky) on Project Legal-Case-Identification (LCI):** Developed a Gen-AI solution using NLP, GPT, and Prompt Engineering to automate legal case assignments.

#   * **FM Quotation Request - OCR:** Built an automated OCR model using NLP and Spacy to extract information from quotation documents and streamline the request process.

#   * **Concrete Strength Prediction:** Developed a regression model using XGBoost Regressor to predict concrete compressive strength based on mixture components.

#   * **Webshop - Customer Reviews Sentiments:** Implemented a sentiment analysis model using NLP techniques to classify customer reviews and generate reports.

#   

#   ## Mentorship

#   

#   * **Data Science Tutor:** Provided tutoring in Programming, Data Science, Machine Learning, and Data Visualization.

#   

#   ## Certifications

#   

#   * **Oracle Cloud Infrastructure 2024 Generative AI Certified Professional:** [Link](Link)

#   * **Gold Badge (5 Star) for Python on HackerRank:** [Link]

#   * **Data Scientist 1-year Master Professional Program:** [Link]

#   * **Certificate of Training in Machine Learning Advanced Course:** [Link]

#   

#   ```[0m

#   

#   [1m> Finished chain.[0m

#   You:  exit

#   

#   Starting the Resume create session. Type 'exit' to end the session.

#   

#   Ending the conversation. Goodbye!

#   File 'Agent_output\Resume_20241117173459.md' created successfully.

#   Resume saved to Agent_output\Resume_20241117173459.md

#   <IPython.core.display.Markdown object>
#   {'category': '2\n', 'response': 'Agent_output\\Resume_20241117173459.md'}

"""
## TEST CASE 6: Resume Making
"""

query = "I want to make resume for Gen AI roles job."
result = run_user_query(query)
result
# Output:
#   Categorizing the customer query...

#   Category: handle_resume_making

#   

#   Starting the Resume create session. Type 'exit' to end the session.

#   

#   

#   

#   [1m> Entering new AgentExecutor chain...[0m

#   [32;1m[1;3mI can definitely help you with that! To create a tailored resume for Generative AI roles, I need some information from you.  Could you please tell me about your technical skills related to AI/ML and Generative AI in particular?  For example, list specific programming languages, platforms, libraries, and tools you're proficient in (e.g., Python, TensorFlow, PyTorch, Transformers, LangChain, etc.).

#   [0m

#   

#   [1m> Finished chain.[0m

#   You:  Skills ____________________________________________________________________________________________ â€¢ Python | SQL | C# | Tensorflow | Pytorch | Numpy | NLTK | Pandas | Natural Language Processing | Machine Learning| Database query | â€¢ Computer Vision | Transformers | MXNet | Deep Learning | Anomaly detection | Scikit-learn | CNN | RNN | LSTM -Neural networks | â€¢ AWS | JavaScript | REST API | LLMs-Large Language Models | Keras | Predictive Modeling | Generative AI | Prompt Engineering | Neo4j â€¢ Tableau | Power BI | Fine Tuning | Problem solving | Web Development | PySpark | GCP | Azure | Statistics | Statistical modeling | R

#   

#   Starting the Resume create session. Type 'exit' to end the session.

#   

#   

#   

#   [1m> Entering new AgentExecutor chain...[0m

#   [32;1m[1;3mGreat!  Now, please tell me about your work experience and projects, focusing on those relevant to Generative AI.  For each experience/project, please provide a brief description, highlighting your contributions and the technologies used.  If you have any publications or patents, please mention those as well.  If you're a fresh graduate or have no direct experience, describe relevant academic projects or coursework.

#   [0m

#   

#   [1m> Finished chain.[0m

#   You:  Experience _______________________________________________________________________________________ Senior Data Scientist FreightMango Gurgaon, India 06/2023 â€“ 12/2023 â€¢ Applied data preprocessing techniques, including data collection and cleaning, to prepare datasets for Machine learning models. â€¢ Tuned and optimized datasets through advanced data preprocessing techniques for machine learning models. â€¢ Engineered an automated customer quotation document scanning pipeline, boosting customer acquisition by 40%. â€¢ Drive the vision of the product, ensuring alignment with business goals. Implement networking protocols and ensure robust product security. Conducted research to identify industry trends, applying findings to product innovation. â€¢ Applied machine learning (ML) algorithms to optimize finance-related applications, enhancing the accuracy and efficiency of financial forecasting models.Software Engineer DataNova Noida, India 02/2019 - 06/2023 â€¢ Conducted image annotation, text data cleaning, text vectorization, manipulation, and data preprocessing for Machine learning projects. â€¢ Feature Engineering and created data visualizations to support data-driven decisions. Execute on design, build, analysis and validation of  data analytics, modeling, and machine learning techniques â€¢ In-depth expertise with a rich repertoire of Regression, Classification, Clustering, and Dimensionality reduction algorithms. â€¢ Delivered pre-trained and fine-tuned neural network models using TensorFlow for internal projects, including object detection and automated chatbots using NLP. â€¢ Collaborated with cross-functional teams to deploy machine learning solutions, enhancing performance for perception tasks like Object  Detection.  Projects __________________________________________________________________________________________ â€¢ WAFER SENSOR FAULT CLASSIFICATION: Predict the quality of the wafer whether good or bad based on the different sensor values for each wafer. A wafer is a thin semiconductor used in various electronic devices. Technology: Python, SQL, Machine learning, RandomForest Classifier, Data Validation, Preprocessing, K Means++ Clustering, Classification, Hyperparameter tuning. â€¢ HAND DETECTION-Shredder Machine: Detect the hands of the workers working with the shredder machine and stop the machine if hands come near the machine to prevent injury. Technology: Python, SQL, Tensorflow object detection framework-SSDlite â€¢ ANPR (Automatic Number Plate Recognition): Worked on end-to-end ANPR for NPCI , installed on Mumbai Marine Lines running on real time. ANPR is Automatic Number Plate Recognition system , Purpose for this Solution is to replace Fastag and convert all toll services with ANPR solution. Technology: Computer vision, Transfer learning, Deepstream, Docker, GCP, Yolo, Tracker, paddel, dbnet, OCR(CRNN, paddel OCR,tensorRT), ML-Flow, Python, OpenCV, Pandas. â€¢ VERINEXT(PondLehocky) on Project Legal-Case-Identification (LCI): LCI( Legal-Case-Identification) is a legal domain project , This Solution is for US legal firms to replace their Manual processes to assign case to suitable handling firm with Gen-AI solution with Littify DB. Technology: Gen-AI, NLP, GPT, Prompt engineering, LangChain, Authentication API , Litify, Deep learning Algo, AZURE-API.  

#   

#   Starting the Resume create session. Type 'exit' to end the session.

#   

#   

#   

#   [1m> Entering new AgentExecutor chain...[0m

#   [32;1m[1;3mOkay, that's a good start.  Finally, could you please provide your education details (degrees, university, graduation dates), any relevant certifications (e.g., AWS Certified Machine Learning â€“ Specialty), and your contact information (name, phone number, email, LinkedIn profile URL if you have one)?  You can replace your actual contact information with placeholders if you prefer not to share it here.

#   

#   [0m

#   

#   [1m> Finished chain.[0m

#   You:  Education ________________________________________________________________________________________ Master of Science San Francisco Bay University Fremont, CA, USA 01/2024 - Present â€¢ Major in Computer Science (3.93 GPA) Bachelor of Science ITS Engineering College Greater Noida, India 05/2015 - 06/2019 â€¢ Major in Computer Science & Engineering (3.62 GPA)

#   

#   Starting the Resume create session. Type 'exit' to end the session.

#   

#   

#   

#   [1m> Entering new AgentExecutor chain...[0m

#   [32;1m[1;3m```markdown

#   # [Your Name]

#   [Phone Number] | [Email Address] | [LinkedIn Profile URL]

#   

#   ## Summary

#   

#   Highly motivated and results-oriented AI Engineer with a proven track record in developing and deploying Generative AI solutions. Expertise in leveraging cutting-edge technologies like LLMs, Transformers, and Deep Learning to solve complex business problems. Passionate about building innovative and impactful AI-driven applications.

#   

#   ## Skills

#   

#   **Programming Languages:** Python, SQL, C#, JavaScript, R

#   **AI/ML Libraries & Frameworks:** TensorFlow, PyTorch, Keras, Scikit-learn, Transformers, LangChain, NLTK, Pandas, NumPy, MXNet

#   **Cloud Platforms:** AWS, GCP, Azure

#   **Databases:** SQL, Neo4j

#   **Other Tools & Technologies:**  Computer Vision, CNN, RNN, LSTM, Natural Language Processing (NLP), Deep Learning, Predictive Modeling, Generative AI, Prompt Engineering, Fine-tuning, REST API, Tableau, Power BI, PySpark, Docker, Deepstream

#   

#   ## Experience

#   

#   **Senior Data Scientist, FreightMango (Gurgaon, India)**  06/2023 â€“ 12/2023

#   * Engineered an automated customer quotation document scanning pipeline, boosting customer acquisition by 40%.

#   * Applied data preprocessing techniques, including data collection and cleaning, to prepare datasets for Machine learning models.

#   * Tuned and optimized datasets through advanced data preprocessing techniques for machine learning models.

#   * Applied machine learning (ML) algorithms to optimize finance-related applications, enhancing the accuracy and efficiency of financial forecasting models.

#   * Drove the product vision, ensuring alignment with business goals. Implemented networking protocols and ensured robust product security.

#   * Conducted research to identify industry trends, applying findings to product innovation.

#   

#   

#   **Software Engineer, DataNova (Noida, India)** 02/2019 - 06/2023

#   * Conducted image annotation, text data cleaning, text vectorization, manipulation, and data preprocessing for Machine learning projects.

#   * Feature Engineering and created data visualizations to support data-driven decisions. Executed design, build, analysis and validation of data analytics, modeling, and machine learning techniques.

#   * In-depth expertise with a rich repertoire of Regression, Classification, Clustering, and Dimensionality reduction algorithms.

#   * Delivered pre-trained and fine-tuned neural network models using TensorFlow for internal projects, including object detection and automated chatbots using NLP.

#   * Collaborated with cross-functional teams to deploy machine learning solutions, enhancing performance for perception tasks like Object Detection.

#   

#   

#   ## Projects

#   

#   * **VERINEXT (PondLehocky) on Project Legal-Case-Identification (LCI):** Developed a Generative AI solution for US legal firms to automate case assignment using the Littify database.  Technologies: Gen-AI, NLP, GPT, Prompt engineering, LangChain, Authentication API, Litify, Deep learning algorithms, Azure API.

#   * **ANPR (Automatic Number Plate Recognition):** Developed an end-to-end ANPR system for NPCI, deployed on Mumbai Marine Lines, running in real-time, to replace Fastag and convert toll services to ANPR. Technologies: Computer vision, Transfer learning, Deepstream, Docker, GCP, Yolo, Tracker, PaddleOCR, DBNet, OCR (CRNN, PaddleOCR, TensorRT), MLflow, Python, OpenCV, Pandas.

#   * **HAND DETECTION-Shredder Machine:** Developed a hand detection system using TensorFlow Object Detection framework (SSDlite) to prevent injuries by stopping the shredder machine when hands come near. Technologies: Python, SQL, TensorFlow Object Detection framework-SSDlite.

#   * **WAFER SENSOR FAULT CLASSIFICATION:** Developed a model to predict wafer quality based on sensor values. Technologies: Python, SQL, Machine learning, RandomForest Classifier, Data Validation, Preprocessing, K-Means++ Clustering, Classification, Hyperparameter tuning.

#   

#   ## Education

#   

#   * **Master of Science in Computer Science,** San Francisco Bay University (Fremont, CA, USA)  01/2024 - Present (GPA: 3.93)

#   * **Bachelor of Science in Computer Science & Engineering,** ITS Engineering College (Greater Noida, India) 05/2015 - 06/2019 (GPA: 3.62)

#   

#   

#   ```

#   [0m

#   

#   [1m> Finished chain.[0m

#   You:  exit

#   

#   Starting the Resume create session. Type 'exit' to end the session.

#   

#   Ending the conversation. Goodbye!

#   File 'Agent_output\Resume_20241117162047.md' created successfully.

#   Resume saved to Agent_output\Resume_20241117162047.md

#   <IPython.core.display.Markdown object>
#   {'category': '2\n', 'response': 'Agent_output\\Resume_20241117162047.md'}

"""
## TEST CASE 7: Job Search
"""

query = "I want to search jobs."

result = run_user_query(query)
result
# Output:
#   Categorizing the customer query...

#   Category: job_search

#   Please make sure to mention Job location you want,Job roles

#    Find jobs in GenAI, AI Engineer roles, Location USA

#   File 'Agent_output\Job_search_20241117172655.md' created successfully.

#   Jobs saved to Agent_output\Job_search_20241117172655.md

#   <IPython.core.display.Markdown object>
#   {'category': '4\n', 'response': 'Agent_output\\Job_search_20241117172655.md'}


